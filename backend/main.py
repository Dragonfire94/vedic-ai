#!/usr/bin/env python3
"""
ë² ë”• ì ì„±í•™ ë°±ì—”ë“œ (FastAPI)
- ì°¨íŠ¸ ê³„ì‚°: Swiss Ephemeris + Lahiri Ayanamsa
- AI ë¦¬ë”©: OpenAI GPT
- PDF ë¦¬í¬íŠ¸: ReportLab (Pretendard í°íŠ¸ ì§€ì›)
"""

import os
import json
import math
import base64
from datetime import datetime
from typing import Optional, Any, Literal, Tuple, Dict, List

from astro_engine import build_structural_summary

import swisseph as swe
import pytz
from timezonefinder import TimezoneFinder
from openai import OpenAI

from fastapi import FastAPI, Query, Response, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from pydantic import AliasChoices, BaseModel, Field, model_validator

# ReportLab PDF ìƒì„±
from reportlab.lib import colors
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import cm
from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY
from reportlab.platypus import (
    SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle,
    PageBreak, KeepTogether, Flowable
)
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ ë³€ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Pretendard í°íŠ¸ ë“±ë¡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FONT_DIR = os.path.join(os.path.dirname(__file__), 'fonts')
FONT_REGULAR = os.path.join(FONT_DIR, 'Pretendard-Regular.ttf')
FONT_BOLD = os.path.join(FONT_DIR, 'Pretendard-Bold.ttf')

KOREAN_FONT_AVAILABLE = False
PDF_FONT_REG = 'Helvetica'
PDF_FONT_BOLD = 'Helvetica-Bold'
PDF_FONT_MONO = 'Courier'


def init_fonts() -> None:
    """PDF í°íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³  ì‹¤íŒ¨ ì‹œ Helveticaë¡œ ì•ˆì „í•˜ê²Œ fallback í•œë‹¤."""
    global KOREAN_FONT_AVAILABLE, PDF_FONT_REG, PDF_FONT_BOLD, PDF_FONT_MONO

    # ê¸°ë³¸ fallback ê°’
    KOREAN_FONT_AVAILABLE = False
    PDF_FONT_REG = 'Helvetica'
    PDF_FONT_BOLD = 'Helvetica-Bold'
    PDF_FONT_MONO = 'Courier'

    try:
        if not (os.path.exists(FONT_REGULAR) and os.path.exists(FONT_BOLD)):
            raise FileNotFoundError(f"Pretendard fonts not found in {FONT_DIR}")

        pdfmetrics.registerFont(TTFont('Pretendard', FONT_REGULAR))
        pdfmetrics.registerFont(TTFont('Pretendard-Bold', FONT_BOLD))
        KOREAN_FONT_AVAILABLE = True
        PDF_FONT_REG = 'Pretendard'
        PDF_FONT_BOLD = 'Pretendard-Bold'
        PDF_FONT_MONO = 'Pretendard'
        print("[INFO] Pretendard fonts loaded successfully")
    except Exception as e:
        print(f"[WARN] Font initialization failed. Fallback to Helvetica: {e}")


init_fonts()

app = FastAPI(title="Vedic AI Backend")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OpenAI í´ë¼ì´ì–¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
client = None
if OPENAI_API_KEY:
    try:
        client = OpenAI(api_key=OPENAI_API_KEY)
    except Exception as e:
        print(f"[WARN] OpenAI client initialization failed: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AI ìºì‹œ (ë©”ëª¨ë¦¬)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AI_CACHE = {}
AI_CACHE_TTL = 1800  # 30ë¶„

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì •ì  í•´ì„ ë°ì´í„° ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INTERPRETATION_FILE = os.path.join(
    os.path.dirname(os.path.dirname(__file__)),
    "assets", "data", "interpretations.kr_final.json"
)
INTERPRETATIONS_DATA: dict[str, Any] | None = None
INTERPRETATIONS_KO: dict[str, Any] = {}
INTERPRETATIONS_ATOMIC_KO: dict[str, Any] = {}
INTERPRETATIONS_LOAD_ERROR: str | None = None

try:
    with open(INTERPRETATION_FILE, "r", encoding="utf-8") as f:
        INTERPRETATIONS_DATA = json.load(f)
    INTERPRETATIONS_KO = (INTERPRETATIONS_DATA.get("ko") or {})
    INTERPRETATIONS_ATOMIC_KO = INTERPRETATIONS_KO.get("atomic") or {}
    if not isinstance(INTERPRETATIONS_ATOMIC_KO, dict):
        INTERPRETATIONS_LOAD_ERROR = "ko.atomic is not a dictionary"
        INTERPRETATIONS_ATOMIC_KO = {}
except Exception as e:
    INTERPRETATIONS_LOAD_ERROR = str(e)
    print(f"[WARN] interpretations file load failed: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Swiss Ephemeris ì´ˆê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
swe.set_ephe_path(None)
swe.set_sid_mode(swe.SIDM_LAHIRI)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒìˆ˜: í–‰ì„±, ë¼ì‹œ, ë‚˜í¬ìƒ¤íŠ¸ë¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PLANET_IDS = {
    "Sun": swe.SUN,
    "Moon": swe.MOON,
    "Mars": swe.MARS,
    "Mercury": swe.MERCURY,
    "Jupiter": swe.JUPITER,
    "Venus": swe.VENUS,
    "Saturn": swe.SATURN,
}
RAHU_KETU_IDS = {
    "Rahu": swe.MEAN_NODE,
    "Ketu": swe.MEAN_NODE,
}

RASI_NAMES = [
    "Aries", "Taurus", "Gemini", "Cancer", "Leo", "Virgo",
    "Libra", "Scorpio", "Sagittarius", "Capricorn", "Aquarius", "Pisces"
]
RASI_NAMES_KR = [
    "ì–‘ìë¦¬", "í™©ì†Œìë¦¬", "ìŒë‘¥ì´ìë¦¬", "ê²Œìë¦¬", "ì‚¬ììë¦¬", "ì²˜ë…€ìë¦¬",
    "ì²œì¹­ìë¦¬", "ì „ê°ˆìë¦¬", "ê¶ìˆ˜ìë¦¬", "ì—¼ì†Œìë¦¬", "ë¬¼ë³‘ìë¦¬", "ë¬¼ê³ ê¸°ìë¦¬"
]

NAKSHATRA_NAMES = [
    "Ashwini", "Bharani", "Krittika", "Rohini", "Mrigashira", "Ardra",
    "Punarvasu", "Pushya", "Ashlesha", "Magha", "Purva Phalguni", "Uttara Phalguni",
    "Hasta", "Chitra", "Swati", "Vishakha", "Anuradha", "Jyeshtha",
    "Mula", "Purva Ashadha", "Uttara Ashadha", "Shravana", "Dhanishta", "Shatabhisha",
    "Purva Bhadrapada", "Uttara Bhadrapada", "Revati"
]

HOUSE_SYSTEMS = {
    "P": "Placidus",
    "W": "Whole Sign",
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Pydantic ëª¨ë¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class BTREvent(BaseModel):
    event_type: str = Field(
        ...,
        description="ì´ë²¤íŠ¸ íƒ€ì… (ì˜ˆ: marriage, career, education)",
        validation_alias=AliasChoices("event_type", "type"),
    )
    precision_level: Literal["exact", "range", "unknown"] = Field(
        "exact",
        description="ì •ë°€ë„ ë ˆë²¨ (exact | range | unknown)",
    )
    year: Optional[int] = Field(None, description="ì´ë²¤íŠ¸ ë°œìƒ ë…„ë„")
    month: Optional[int] = Field(None, description="ì´ë²¤íŠ¸ ë°œìƒ ì›” (ì„ íƒ)")
    age_range: Optional[Tuple[int, int]] = Field(None, description="ì´ë²¤íŠ¸ ë‚˜ì´ êµ¬ê°„ (ì‹œì‘, ì¢…ë£Œ)")
    weight: Optional[float] = Field(1.0, description="ì´ë²¤íŠ¸ ê°€ì¤‘ì¹˜")
    dasha_lords: Optional[list[str]] = Field(default_factory=list, description="ë‹¤ìƒ¤ ë¡œë“œ")
    house_triggers: Optional[list[int]] = Field(default_factory=list, description="í•˜ìš°ìŠ¤ íŠ¸ë¦¬ê±°")

    @model_validator(mode="after")
    def validate_precision_payload(self) -> "BTREvent":
        """precision_levelì— ë§ëŠ” ì´ë²¤íŠ¸ ì…ë ¥ ì¡°í•©ì„ ê²€ì¦í•œë‹¤."""
        if self.month is not None and not (1 <= self.month <= 12):
            raise ValueError("monthëŠ” 1~12 ë²”ìœ„ì—¬ì•¼ í•©ë‹ˆë‹¤.")

        if self.precision_level == "exact":
            if self.year is None:
                raise ValueError("precision_level='exact' ì¸ ê²½ìš° yearëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
            if self.age_range is not None:
                raise ValueError("precision_level='exact' ì¸ ê²½ìš° age_rangeëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        elif self.precision_level == "range":
            if self.age_range is None:
                raise ValueError("precision_level='range' ì¸ ê²½ìš° age_rangeëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
            start_age, end_age = self.age_range
            if start_age < 0 or end_age < 0:
                raise ValueError("age_range ê°’ì€ 0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            if start_age > end_age:
                raise ValueError("age_range ì‹œì‘ê°’ì€ ì¢…ë£Œê°’ë³´ë‹¤ í´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            if self.year is not None:
                raise ValueError("precision_level='range' ì¸ ê²½ìš° yearëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            if self.month is not None:
                raise ValueError("precision_level='range' ì¸ ê²½ìš° monthëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        elif self.precision_level == "unknown":
            if self.year is not None or self.age_range is not None or self.month is not None:
                raise ValueError("precision_level='unknown' ì¸ ê²½ìš° year/month/age_rangeëŠ” ëª¨ë‘ ë¹„ì›Œì•¼ í•©ë‹ˆë‹¤.")

        return self

class BTRAnalyzeRequest(BaseModel):
    year: int = Field(..., description="ì¶œìƒ ë…„ë„")
    month: int = Field(..., ge=1, le=12, description="ì¶œìƒ ì›”")
    day: int = Field(..., ge=1, le=31, description="ì¶œìƒ ì¼")
    lat: float = Field(..., description="ìœ„ë„")
    lon: float = Field(..., description="ê²½ë„")
    events: list[BTREvent] = Field(..., description="ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸")

class BTRRefineRequest(BaseModel):
    year: int = Field(..., description="ì¶œìƒ ë…„ë„")
    month: int = Field(..., ge=1, le=12, description="ì¶œìƒ ì›”")
    day: int = Field(..., ge=1, le=31, description="ì¶œìƒ ì¼")
    lat: float = Field(..., description="ìœ„ë„")
    lon: float = Field(..., description="ê²½ë„")
    bracket_start: float = Field(..., description="ë¸Œë˜í‚· ì‹œì‘ ì‹œê°„")
    bracket_end: float = Field(..., description="ë¸Œë˜í‚· ì¢…ë£Œ ì‹œê°„")
    events: list[BTREvent] = Field(..., description="ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í—¬í¼ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_360(deg: float) -> float:
    """ê°ë„ë¥¼ 0~360 ë²”ìœ„ë¡œ ì •ê·œí™”"""
    while deg < 0:
        deg += 360
    while deg >= 360:
        deg -= 360
    return deg

def get_rasi_index(lon: float) -> int:
    """0~11 ë¼ì‹œ ì¸ë±ìŠ¤"""
    return int(lon / 30.0) % 12

def get_nakshatra_info(lon: float):
    """ë‚˜í¬ìƒ¤íŠ¸ë¼ ì •ë³´ (0~26, pada 1~4)"""
    nak_idx = int(lon / (360.0 / 27))
    nak_name = NAKSHATRA_NAMES[nak_idx]
    deg_in_nak = lon - (nak_idx * (360.0 / 27))
    pada = int(deg_in_nak / (360.0 / 27 / 4)) + 1
    return {"index": nak_idx, "name": nak_name, "pada": pada}

def get_dignity(planet_name: str, rasi_idx: int, lon: float) -> str:
    """ê°„ë‹¨í•œ Dignity íŒë‹¨ (Own/Exalted/Debilitated/Neutral)"""
    rules = {
        "Sun": {"own": [4], "exalted": [0], "debilitated": [6]},
        "Moon": {"own": [3], "exalted": [1], "debilitated": [7]},
        "Mars": {"own": [0, 7], "exalted": [9], "debilitated": [3]},
        "Mercury": {"own": [2, 5], "exalted": [5], "debilitated": [11]},
        "Jupiter": {"own": [8, 11], "exalted": [3], "debilitated": [9]},
        "Venus": {"own": [1, 6], "exalted": [11], "debilitated": [5]},
        "Saturn": {"own": [9, 10], "exalted": [6], "debilitated": [0]},
    }
    r = rules.get(planet_name, {})
    if rasi_idx in r.get("own", []):
        return "Own"
    if rasi_idx in r.get("exalted", []):
        return "Exalted"
    if rasi_idx in r.get("debilitated", []):
        return "Debilitated"
    return "Neutral"

def is_combust(planet_name: str, planet_lon: float, sun_lon: float) -> bool:
    """ì—°ì†Œ(Combust) íŒë‹¨"""
    if planet_name == "Sun":
        return False
    thresholds = {
        "Moon": 12, "Mars": 17, "Mercury": 14,
        "Jupiter": 11, "Venus": 10, "Saturn": 15
    }
    threshold = thresholds.get(planet_name, 10)
    diff = abs(normalize_360(planet_lon - sun_lon))
    if diff > 180:
        diff = 360 - diff
    return diff < threshold

def compute_julian_day(year: int, month: int, day: int, hour_frac: float, lat: float, lon: float) -> float:
    """ìœ¨ë¦¬ìš°ìŠ¤ì¼ ê³„ì‚° (UTC ë³€í™˜)"""
    # ìœ„ë„/ê²½ë„ë¡œ íƒ€ì„ì¡´ ìë™ ê²°ì •
    tf = TimezoneFinder()
    tz_name = tf.timezone_at(lat=lat, lng=lon)
    if not tz_name:
        tz_name = 'UTC'  # íƒ€ì„ì¡´ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ UTC ì‚¬ìš©
    tz = pytz.timezone(tz_name)

    local_dt = datetime(year, month, day, int(hour_frac), int((hour_frac % 1) * 60))
    local_dt = tz.localize(local_dt)
    utc_dt = local_dt.astimezone(pytz.utc)

    # ğŸ” ë””ë²„ê·¸: ì‹œê°„ ë³€í™˜ í™•ì¸
    print(f"ğŸ” Timezone: {tz_name}")
    print(f"ğŸ” Local time: {local_dt}")
    print(f"ğŸ” UTC time: {utc_dt}")

    jd = swe.julday(utc_dt.year, utc_dt.month, utc_dt.day,
                    utc_dt.hour + utc_dt.minute / 60.0 + utc_dt.second / 3600.0)
    print(f"ğŸ” Julian day: {jd}")
    return jd

def extract_atomic_interpretation_text(entry: Any) -> str | None:
    """í•´ì„ ì—”íŠ¸ë¦¬(dict/str)ì—ì„œ textë¥¼ ì¶”ì¶œ"""
    if isinstance(entry, dict):
        text = entry.get("text")
        if isinstance(text, str) and text.strip():
            return text.strip()
    elif isinstance(entry, str) and entry.strip():
        return entry.strip()
    return None


def build_atomic_keys_from_chart(chart: dict) -> list[str]:
    """ì°¨íŠ¸ì—ì„œ atomic ì¡°íšŒ í‚¤ë¥¼ ìƒì„±í•œë‹¤."""
    keys: list[str] = []

    asc_sign = (((chart.get("houses") or {}).get("ascendant") or {}).get("rasi") or {}).get("name")
    if isinstance(asc_sign, str) and asc_sign:
        keys.append(f"asc:{asc_sign}")

    for planet_name, pdata in (chart.get("planets") or {}).items():
        sign_name = ((pdata.get("rasi") or {}).get("name"))
        if isinstance(sign_name, str) and sign_name:
            keys.append(f"ps:{planet_name}:{sign_name}")

        house_num = pdata.get("house")
        if isinstance(house_num, int):
            keys.append(f"ph:{planet_name}:{house_num}")

    # ìˆœì„œ ìœ ì§€ ì¤‘ë³µ ì œê±°
    return list(dict.fromkeys(keys))


def yoga_name_to_key(yoga_name: str) -> str:
    """ì°¨íŠ¸ yoga ì´ë¦„ì„ ë°ì´í„° í‚¤ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”"""
    cleaned = yoga_name.replace("Yoga", "").replace("yoga", "").strip()
    cleaned = ''.join(ch for ch in cleaned if ch.isalnum())
    return f"yoga:{cleaned}" if cleaned else ""


def collect_interpretation_context(chart: dict) -> tuple[list[str], list[str], dict[str, int]]:
    """ì°¨íŠ¸ì— ëŒ€ì‘í•˜ëŠ” í•´ì„ í…ìŠ¤íŠ¸ë¥¼ ì„¹ì…˜ë³„ë¡œ ìˆ˜ì§‘í•´ RAG contextë¥¼ êµ¬ì„±"""
    keys: list[str] = []
    texts: list[str] = []
    section_counts = {"atomic": 0, "lagna_lord": 0, "yogas": 0, "patterns": 0}

    ko_data = INTERPRETATIONS_KO if isinstance(INTERPRETATIONS_KO, dict) else {}

    # 1) atomic: asc / planet-sign / planet-house
    atomic = ko_data.get("atomic") or {}
    if isinstance(atomic, dict):
        for key in build_atomic_keys_from_chart(chart):
            text = extract_atomic_interpretation_text(atomic.get(key))
            if text:
                keys.append(key)
                texts.append(text)
                section_counts["atomic"] += 1

    # 2) yogas: chart.features.yogas hit ê¸°ë°˜ ë§¤í•‘
    yogas = ko_data.get("yogas") or {}
    if isinstance(yogas, dict):
        for yoga in (((chart.get("features") or {}).get("yogas")) or []):
            if not isinstance(yoga, dict) or not yoga.get("hit"):
                continue
            yoga_name = yoga.get("name")
            if not isinstance(yoga_name, str):
                continue
            yoga_key = yoga_name_to_key(yoga_name)
            if not yoga_key:
                continue
            text = extract_atomic_interpretation_text(yogas.get(yoga_key))
            if text:
                keys.append(yoga_key)
                texts.append(text)
                section_counts["yogas"] += 1

    # 3) patterns: chart.features.patternsê°€ ì¡´ì¬í•  ê²½ìš°ë§Œ ì‚¬ìš© (í™•ì¥ ëŒ€ë¹„)
    patterns = ko_data.get("patterns") or {}
    if isinstance(patterns, dict):
        for pat in (((chart.get("features") or {}).get("patterns")) or []):
            if isinstance(pat, str):
                pat_key = pat if pat.startswith("pat:") else f"pat:{pat}"
            elif isinstance(pat, dict):
                raw_key = pat.get("id") or pat.get("key") or pat.get("name")
                if not isinstance(raw_key, str):
                    continue
                pat_key = raw_key if raw_key.startswith("pat:") else f"pat:{raw_key}"
            else:
                continue
            text = extract_atomic_interpretation_text(patterns.get(pat_key))
            if text:
                keys.append(pat_key)
                texts.append(text)
                section_counts["patterns"] += 1

    # 4) lagna_lord: chart.features.lagna_lord_keysê°€ ì¡´ì¬í•  ê²½ìš° í™•ì¥ ì‚¬ìš©
    lagna_lord = ko_data.get("lagna_lord") or {}
    if isinstance(lagna_lord, dict):
        for ll_key in (((chart.get("features") or {}).get("lagna_lord_keys")) or []):
            if not isinstance(ll_key, str):
                continue
            key = ll_key if ll_key.startswith("ll:") else f"ll:{ll_key}"
            text = extract_atomic_interpretation_text(lagna_lord.get(key))
            if text:
                keys.append(key)
                texts.append(text)
                section_counts["lagna_lord"] += 1

    dedup_keys = list(dict.fromkeys(keys))
    dedup_texts = list(dict.fromkeys(texts))
    return dedup_keys, dedup_texts, section_counts

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—”ë“œí¬ì¸íŠ¸: Health Check
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/health")
def health():
    return {
        "status": "ok",
        "openai_configured": bool(client),
        "model": OPENAI_MODEL,
        "ai_cache_items": len(AI_CACHE),
        "ai_cache_ttl_sec": AI_CACHE_TTL,
        "korean_font": KOREAN_FONT_AVAILABLE,
        "pdf_font_reg": PDF_FONT_REG,
        "pdf_font_bold": PDF_FONT_BOLD,
        "pdf_font_mono": PDF_FONT_MONO,
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—”ë“œí¬ì¸íŠ¸: Presets (í•˜ë“œì½”ë”© ì˜ˆì‹œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/presets")
def get_presets():
    return {
        "presets": [
            {
                "id": "my_birth",
                "label": "ë‚´ ì¶œìƒì •ë³´",
                "year": 1994,
                "month": 12,
                "day": 18,
                "hour": 23.75,
                "lat": 37.5665,
                "lon": 126.9780
            }
        ]
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—”ë“œí¬ì¸íŠ¸: ì°¨íŠ¸ ê³„ì‚°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/chart")
def get_chart(
    year: int = Query(...),
    month: int = Query(...),
    day: int = Query(...),
    hour: float = Query(...),
    lat: float = Query(...),
    lon: float = Query(...),
    house_system: str = Query("W"),  # Vedic uses Whole Sign by default
    include_nodes: int = Query(1),
    include_d9: int = Query(0),
    include_interpretation: int = Query(0),
    gender: str = Query("male")
):
    """ë² ë”• ì°¨íŠ¸ ê³„ì‚°"""
    # ğŸ” ë””ë²„ê·¸: ì‹¤ì œë¡œ ë°›ì€ íŒŒë¼ë¯¸í„° ì¶œë ¥
    print(f"ğŸ” DEBUG - Received parameters:")
    print(f"   year={year}, month={month}, day={day}, hour={hour}")
    print(f"   lat={lat}, lon={lon}")
    print(f"   house_system={house_system}, gender={gender}")

    try:
        jd = compute_julian_day(year, month, day, hour, lat, lon)
        
        # í–‰ì„± ê³„ì‚°
        planets = {}
        sun_lon = None

        for name, pid in PLANET_IDS.items():
            res, _ = swe.calc_ut(jd, pid, swe.FLG_SIDEREAL)
            p_lon = normalize_360(res[0])
            if name == "Sun":
                sun_lon = p_lon

            rasi_idx = get_rasi_index(p_lon)
            nak = get_nakshatra_info(p_lon)
            deg_in_sign = p_lon - (rasi_idx * 30)

            planets[name] = {
                "longitude": round(p_lon, 6),
                "rasi": {
                    "index": rasi_idx,
                    "name": RASI_NAMES[rasi_idx],
                    "name_kr": RASI_NAMES_KR[rasi_idx],
                    "deg_in_sign": round(deg_in_sign, 2)
                },
                "nakshatra": nak,
                "features": {
                    "dignity": get_dignity(name, rasi_idx, p_lon),
                    "retrograde": res[3] < 0,
                    "combust": False  # ë‚˜ì¤‘ì— ê³„ì‚°
                }
            }
        
        # Combustion ì¬ê³„ì‚°
        if sun_lon is not None:
            for name in planets:
                if name != "Sun":
                    planets[name]["features"]["combust"] = is_combust(
                        name, planets[name]["longitude"], sun_lon
                    )
        
        # Rahu/Ketu
        if include_nodes:
            rahu_res, _ = swe.calc_ut(jd, swe.MEAN_NODE, swe.FLG_SIDEREAL)
            rahu_lon = normalize_360(rahu_res[0])
            ketu_lon = normalize_360(rahu_lon + 180)

            for name, p_lon in [("Rahu", rahu_lon), ("Ketu", ketu_lon)]:
                rasi_idx = get_rasi_index(p_lon)
                nak = get_nakshatra_info(p_lon)
                deg_in_sign = p_lon - (rasi_idx * 30)
                
                planets[name] = {
                    "longitude": round(p_lon, 6),
                    "rasi": {
                        "index": rasi_idx,
                        "name": RASI_NAMES[rasi_idx],
                        "name_kr": RASI_NAMES_KR[rasi_idx],
                        "deg_in_sign": round(deg_in_sign, 2)
                    },
                    "nakshatra": nak,
                    "features": {
                        "dignity": "Shadow",
                        "retrograde": True,
                        "combust": False
                    }
                }
        
        # í•˜ìš°ìŠ¤ ê³„ì‚° (Placidus/Whole Sign)
        # Swiss Ephemeris houses()ëŠ” Tropical ì¢Œí‘œë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ Ayanamsaë¥¼ ë¹¼ì„œ Siderealë¡œ ë³€í™˜
        ayanamsa = swe.get_ayanamsa_ut(jd)

        houses = {}
        if house_system == "P":
            # swe.houses() expects DEGREES, not radians!
            print(f"ğŸ” INPUT Lat/Lon (degrees): {lat}, {lon}")
            cusps, ascmc = swe.houses(jd, lat, lon, b'P')
            asc_tropical = ascmc[0]

            # ğŸ” ë””ë²„ê·¸: Houses ê³„ì‚° í™•ì¸
            print(f"ğŸ” Ayanamsa: {ayanamsa}")
            print(f"ğŸ” Tropical Ascendant: {asc_tropical}")
            print(f"ğŸ” Sidereal Ascendant: {normalize_360(asc_tropical - ayanamsa)}")

            # Tropical ìƒìŠ¹ê¶ì—ì„œ Ayanamsaë¥¼ ë¹¼ì„œ Sidereal ìƒìŠ¹ê¶ ê³„ì‚°
            asc_lon = normalize_360(ascmc[0] - ayanamsa)
            for i in range(12):
                # ê° í•˜ìš°ìŠ¤ ì»¤ìŠ¤í”„ë„ Siderealë¡œ ë³€í™˜
                cusp_lon = normalize_360(cusps[i] - ayanamsa)
                rasi_idx = get_rasi_index(cusp_lon)
                houses[f"house_{i+1}"] = {
                    "cusp_longitude": round(cusp_lon, 6),
                    "rasi": RASI_NAMES[rasi_idx]
                }
        else:  # Whole Sign
            # swe.houses() expects DEGREES, not radians!
            cusps, ascmc = swe.houses(jd, lat, lon, b'W')
            asc_tropical = ascmc[0]
            # Tropical ìƒìŠ¹ê¶ì—ì„œ Ayanamsaë¥¼ ë¹¼ì„œ Sidereal ìƒìŠ¹ê¶ ê³„ì‚°
            asc_lon = normalize_360(ascmc[0] - ayanamsa)
            asc_rasi = get_rasi_index(asc_lon)
            for i in range(12):
                rasi_idx = (asc_rasi + i) % 12
                houses[f"house_{i+1}"] = {
                    "cusp_longitude": round((rasi_idx * 30), 6),
                    "rasi": RASI_NAMES[rasi_idx]
                }
        
        # Ascendant
        asc_rasi_idx = get_rasi_index(asc_lon)
        houses["ascendant"] = {
            "longitude": round(asc_lon, 6),
            "rasi": {
                "index": asc_rasi_idx,
                "name": RASI_NAMES[asc_rasi_idx],
                "name_kr": RASI_NAMES_KR[asc_rasi_idx]
            }
        }
        
        # í–‰ì„± í•˜ìš°ìŠ¤ ë°°ì¹˜
        for name, data in planets.items():
            p_lon = data["longitude"]
            if house_system == "P":
                for i in range(12):
                    c1 = houses[f"house_{i+1}"]["cusp_longitude"]
                    c2 = houses[f"house_{(i+1)%12 + 1}"]["cusp_longitude"] if i < 11 else houses["house_1"]["cusp_longitude"]
                    if c1 <= c2:
                        if c1 <= p_lon < c2:
                            data["house"] = i + 1
                            break
                    else:
                        if p_lon >= c1 or p_lon < c2:
                            data["house"] = i + 1
                            break
            else:  # Whole Sign
                p_rasi = data["rasi"]["index"]
                data["house"] = ((p_rasi - asc_rasi_idx) % 12) + 1
        
        # D9 (Navamsa) - ê°„ë‹¨ êµ¬í˜„
        d9_data = None
        if include_d9:
            d9_planets = {}
            for name, data in planets.items():
                p_lon = data["longitude"]
                d9_lon = (p_lon * 9) % 360
                d9_rasi_idx = get_rasi_index(d9_lon)
                d9_planets[name] = {
                    "rasi": RASI_NAMES[d9_rasi_idx],
                    "rasi_kr": RASI_NAMES_KR[d9_rasi_idx]
                }
            d9_data = {"planets": d9_planets}
        
        # ìš”ê°€ (ê°„ë‹¨ ì˜ˆì‹œ)
        yogas = []
        # Budha-Aditya Yoga
        if "Mercury" in planets and "Sun" in planets:
            merc_house = planets["Mercury"].get("house", 0)
            sun_house = planets["Sun"].get("house", 0)
            if merc_house == sun_house:
                yogas.append({
                    "name": "Budha-Aditya Yoga",
                    "hit": True,
                    "note": "Sun and Mercury conjunct"
                })
        
        result = {
            "input": {
                "year": year, "month": month, "day": day, "hour": hour,
                "lat": lat, "lon": lon,
                "house_system": house_system,
                "include_nodes": bool(include_nodes),
                "include_d9": bool(include_d9),
                "gender": gender
            },
            "julian_day": jd,
            "planets": planets,
            "houses": houses,
            "features": {
                "yogas": yogas
            },
            "debug": {
                "ayanamsa": round(ayanamsa, 4),
                "asc_tropical": round(asc_tropical, 4),
                "asc_sidereal": round(asc_lon, 4)
            }
        }
        
        if d9_data:
            result["d9"] = d9_data
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Rectified bridge helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_rectified_chart_payload(
    btr_candidate: dict,
    birth_date: dict,
    latitude: float,
    longitude: float,
    timezone: float,
) -> dict:
    """Build deterministic chart payload from a rectified BTR candidate."""
    del timezone  # reserved for explicit TZ pipeline usage
    mid_hour = float(btr_candidate.get("mid_hour", 0.0))
    return get_chart(
        year=int(birth_date["year"]),
        month=int(birth_date["month"]),
        day=int(birth_date["day"]),
        hour=mid_hour,
        lat=float(latitude),
        lon=float(longitude),
        house_system="W",
        include_nodes=1,
        include_d9=1,
        include_interpretation=0,
        gender="male",
    )


def build_rectified_structural_summary(
    btr_candidates: list,
    birth_date: dict,
    latitude: float,
    longitude: float,
    timezone: float,
) -> dict:
    """Bridge top BTR candidate to deterministic structural summary."""
    if not btr_candidates:
        raise ValueError("No BTR candidates available")

    top_candidate = btr_candidates[0]
    chart_data = build_rectified_chart_payload(
        btr_candidate=top_candidate,
        birth_date=birth_date,
        latitude=latitude,
        longitude=longitude,
        timezone=timezone,
    )
    structural_summary = build_structural_summary(chart_data)

    return {
        "rectified_time_range": top_candidate.get("time_range", ""),
        "rectified_probability": float(top_candidate.get("probability", 0.0)),
        "rectified_confidence": float(top_candidate.get("confidence", 0.0)),
        "structural_summary": structural_summary,
    }


def build_ai_psychological_input(
    rectified_structural_summary: dict,
) -> dict:
    """Build compact AI-safe signal payload (no raw longitude/degree data)."""
    source = rectified_structural_summary.get("structural_summary", {}) or {}
    allowed_keys = [
        "planet_power_ranking",
        "psychological_tension_axis",
        "purushartha_profile",
        "behavioral_risk_profile",
        "stability_metrics",
        "personality_vector",
        "probability_forecast",
        "karmic_pattern_profile",
        "interaction_risks",
        "enhanced_behavioral_risks",
    ]
    return {k: source.get(k, {}) for k in allowed_keys}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—”ë“œí¬ì¸íŠ¸: AI Reading
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/ai_reading")
def get_ai_reading(
    year: int = Query(...),
    month: int = Query(...),
    day: int = Query(...),
    hour: float = Query(...),
    lat: float = Query(...),
    lon: float = Query(...),
    house_system: str = Query("W"),  # Vedic uses Whole Sign by default
    include_nodes: int = Query(1),
    include_d9: int = Query(1),
    language: str = Query("ko"),
    gender: str = Query("male"),
    use_cache: int = Query(1),
    production_mode: int = Query(0),
    events_json: str = Query("[]"),
    timezone: float = Query(0.0),
):
    """AI ë¦¬ë”© ìƒì„±"""
    cache_key = f"{year}_{month}_{day}_{hour}_{lat}_{lon}_{house_system}_{language}_{gender}_{production_mode}_{events_json}_{timezone}"

    if use_cache and cache_key in AI_CACHE:
        cached = AI_CACHE[cache_key]
        if production_mode:
            return cached
        return {
            "cached": True,
            "ai_cache_key": cache_key,
            **cached,
        }

    if production_mode:
        if not BTR_ENGINE_AVAILABLE:
            raise HTTPException(status_code=500, detail="BTR ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        try:
            events = json.loads(events_json) if events_json else []
            if not isinstance(events, list) or not events:
                raise ValueError("production_mode=1 requires non-empty events_json list")

            birth_date = {"year": year, "month": month, "day": day}
            btr_candidates = analyze_birth_time(
                birth_date=birth_date,
                events=events,
                lat=lat,
                lon=lon,
                num_brackets=8,
                top_n=3,
                production_mode=True,
            )

            rectified_summary = build_rectified_structural_summary(
                btr_candidates=btr_candidates,
                birth_date=birth_date,
                latitude=lat,
                longitude=lon,
                timezone=timezone,
            )
            ai_psychological_input = build_ai_psychological_input(rectified_summary)
            ai_payload = {
                "rectified_meta": {
                    "time_range": rectified_summary["rectified_time_range"],
                    "probability": rectified_summary["rectified_probability"],
                    "confidence": rectified_summary["rectified_confidence"],
                },
                "structural_summary": ai_psychological_input,
            }

            if not client:
                final_text = "[OpenAI not configured]"
            else:
                system_message = (
                    "You are not calculating astrology. "
                    "You are interpreting structured psychological signals. "
                    "Use only the provided JSON."
                )
                user_message = f"""Interpret only this JSON payload:
{json.dumps(ai_payload, ensure_ascii=False, indent=2)}

Provide a concise psychological narrative summary."""
                response = client.chat.completions.create(
                    model=OPENAI_MODEL,
                    messages=[
                        {"role": "system", "content": system_message},
                        {"role": "user", "content": user_message},
                    ],
                    temperature=0.6,
                    max_tokens=1200,
                )
                final_text = response.choices[0].message.content

            production_result = {
                "rectified_time_range": rectified_summary["rectified_time_range"],
                "probability": round(float(rectified_summary["rectified_probability"]), 6),
                "confidence": round(float(rectified_summary["rectified_confidence"]), 3),
                "final_psychological_summary": final_text,
            }
            if use_cache:
                AI_CACHE[cache_key] = production_result
            return production_result
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    chart = get_chart(year, month, day, hour, lat, lon, house_system, include_nodes, include_d9, gender=gender)
    structured_summary = build_structural_summary(chart)
    ai_payload = {"structural_summary": structured_summary}

    summary = {
        "language": language,
        "structured_summary": structured_summary,
    }

    if not client:
        reading_text = "[OpenAI not configured]"
        result = {
            "cached": False,
            "fallback": True,
            "model": OPENAI_MODEL,
            "summary": summary,
            "structured_summary": structured_summary,
            "reading": reading_text,
            "ai_cache_key": cache_key,
            "debug_info": {
                "api_key_configured": bool(OPENAI_API_KEY),
                "api_key_length": len(OPENAI_API_KEY) if OPENAI_API_KEY else 0,
                "model_used": OPENAI_MODEL,
                "client_initialized": False,
                "reason": "OpenAI client not initialized",
            },
        }
        if use_cache:
            AI_CACHE[cache_key] = result
        return result

    try:
        mapped_keys: list[str] = []
        mapped_texts: list[str] = []
        mapped_section_counts = {"atomic": 0, "lagna_lord": 0, "yogas": 0, "patterns": 0}
        static_context_used = False
        context_data = ""

        if language == "ko":
            system_message = """ë„ˆëŠ” ì ì„±í•™ êµ¬ì¡° ë°ì´í„°ë¥¼ ì‹¬ë¦¬ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ì‰¬ìš´ ìƒë‹´ ì–¸ì–´ë¡œ í’€ì–´ì£¼ëŠ” ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ë‹¤.

ì¤‘ìš” ì›ì¹™:
- ì œê³µëœ structural_summary ë°ì´í„°ë§Œ ì‚¬ìš©í•œë‹¤.
- ë°ì´í„°ì— ì—†ëŠ” ì‚¬ì‹¤ì„ ë‹¨ì •í•˜ê±°ë‚˜ ì¶”ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤.
- ê³¼ì¥ëœ ì˜ˆì–¸ ëŒ€ì‹  ì‹¤í–‰ ê°€ëŠ¥í•œ í–‰ë™ ì¡°ì–¸ìœ¼ë¡œ ì¬êµ¬ì„±í•œë‹¤.
- ì •ì¤‘í•˜ê³  ë”°ëœ»í•œ ~í•©ë‹ˆë‹¤/~í•˜ì„¸ìš” ì²´ë¥¼ ìœ ì§€í•œë‹¤."""

            user_message = f"""ë‹¤ìŒì€ ë‚´ë‹´ìì˜ êµ¬ì¡° ìš”ì•½ JSONì…ë‹ˆë‹¤.

{json.dumps(ai_payload, ensure_ascii=False, indent=2)}

ë„ˆì˜ ì—­í• : "You are not calculating astrology. You are translating structured psychological signals into deep narrative analysis."

ì•„ë˜ JSONë§Œ ê·¼ê±°ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í•œêµ­ì–´ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
[í•µì‹¬ í…Œë§ˆ] ì‚¶ì˜ ì£¼ì œ í•œ ì¤„ ìš”ì•½
[ì‹¬ë¦¬ ì¶•] ë‚´ì  ê°ˆë“±/ê°•ì  í•´ì„¤
[ê´€ê³„Â·ì»¤ë¦¬ì–´] ê´€ê³„ ë²¡í„°ì™€ ì»¤ë¦¬ì–´ ë²¡í„°ì˜ ì‹¤ì œ ì ìš© ì¡°ì–¸
[í˜„ì¬ ì‹œê¸° ì „ëµ] current_dasha_vector ê¸°ë°˜ ë¦¬ìŠ¤í¬/ê¸°íšŒ ê´€ë¦¬

ìš”êµ¬ì‚¬í•­:
- ì¶”ì¸¡ ê¸ˆì§€, JSON ê·¼ê±° ëª…ì‹œì  ë°˜ì˜
- ì‹¤ì²œ ê°€ëŠ¥í•œ ì¡°ì–¸ ì¤‘ì‹¬
- ê³¼ë„í•œ ìš´ì„¸ ë¬¸êµ¬ ê¸ˆì§€"""
        else:
            system_message = (
                "You are not calculating astrology. You are translating structured psychological signals into deep narrative analysis. "
                "Use only the provided structural_summary JSON, avoid adding external claims, "
                "and provide practical guidance."
            )
            user_message = f"""Role instruction: "You are not calculating astrology. You are translating structured psychological signals into deep narrative analysis."

Use only this structural_summary JSON:
{json.dumps(ai_payload, ensure_ascii=False, indent=2)}

Write a concise, practical English report with sections:
1) Core life theme
2) Psychological axis
3) Relationship and career vectors
4) Current dasha strategy (risk vs opportunity)"""

        response = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message},
            ],
            temperature=0.6,
            max_tokens=3000,
        )

        reading_text = response.choices[0].message.content

        result = {
            "cached": False,
            "fallback": False,
            "model": OPENAI_MODEL,
            "summary": summary,
            "structured_summary": structured_summary,
            "reading": reading_text,
            "ai_cache_key": cache_key,
            "debug_info": {
                "api_key_configured": bool(OPENAI_API_KEY),
                "api_key_length": len(OPENAI_API_KEY) if OPENAI_API_KEY else 0,
                "model_used": OPENAI_MODEL,
                "system_prompt_length": len(system_message),
                "user_prompt_length": len(user_message),
                "context_length": len(context_data),
                "response_tokens": response.usage.total_tokens if hasattr(response, "usage") else 0,
                "client_initialized": client is not None,
                "static_context_used": static_context_used,
                "mapped_key_count": len(mapped_keys),
                "mapped_text_count": len(mapped_texts),
                "mapped_keys": mapped_keys,
                "mapped_section_counts": mapped_section_counts,
                "interpretations_loaded": bool(INTERPRETATIONS_KO),
                "interpretations_load_error": INTERPRETATIONS_LOAD_ERROR,
            },
        }

        if use_cache:
            AI_CACHE[cache_key] = result

        return result

    except Exception as e:
        reading_text = f"[AI Error: {str(e)}]"
        result = {
            "cached": False,
            "fallback": True,
            "error": str(e),
            "model": OPENAI_MODEL,
            "summary": summary,
            "structured_summary": structured_summary,
            "reading": reading_text,
            "ai_cache_key": cache_key,
            "debug_info": {
                "api_key_configured": bool(OPENAI_API_KEY),
                "api_key_length": len(OPENAI_API_KEY) if OPENAI_API_KEY else 0,
                "model_used": OPENAI_MODEL,
                "client_initialized": client is not None,
                "error_type": type(e).__name__,
                "error_message": str(e),
            },
        }
        return result

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PDF ìƒì„± - ë‚¨ì¸ë„ ì°¨íŠ¸ Flowable
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SouthIndianChart(Flowable):
    """ë‚¨ì¸ë„ ìŠ¤íƒ€ì¼ ì°¨íŠ¸ (ë‹¤ì´ì•„ëª¬ë“œí˜•)"""
    def __init__(self, chart_data, width=400, height=400, is_d9=False):
        Flowable.__init__(self)
        self.chart_data = chart_data
        self.width = width
        self.height = height
        self.is_d9 = is_d9
    
    def draw(self):
        c = self.canv
        w, h = self.width, self.height
        cx, cy = w / 2, h / 2
        size = min(w, h) * 0.8
        
        # ë‹¤ì´ì•„ëª¬ë“œ ê·¸ë¦¬ê¸°
        pts = [
            (cx, cy + size/2),      # ìƒë‹¨
            (cx + size/2, cy),      # ìš°ì¸¡
            (cx, cy - size/2),      # í•˜ë‹¨
            (cx - size/2, cy),      # ì¢Œì¸¡
        ]
        
        c.setStrokeColor(colors.black)
        c.setLineWidth(2)
        
        # ì™¸ê³½ì„ 
        p = c.beginPath()
        p.moveTo(pts[0][0], pts[0][1])
        for i in range(1, 4):
            p.lineTo(pts[i][0], pts[i][1])
        p.close()
        c.drawPath(p, stroke=1, fill=0)
        
        # ëŒ€ê°ì„ 
        c.line(pts[0][0], pts[0][1], pts[2][0], pts[2][1])
        c.line(pts[1][0], pts[1][1], pts[3][0], pts[3][1])
        
        # í•˜ìš°ìŠ¤ ë°°ì¹˜ (ë‚¨ì¸ë„ ìŠ¤íƒ€ì¼: 1í•˜ìš°ìŠ¤=ì¤‘ì•™ í•˜ë‹¨)
        houses_layout = [
            (cx, cy - size*0.15),           # 1
            (cx - size*0.25, cy - size*0.3), # 2
            (cx - size*0.35, cy - size*0.1), # 3
            (cx - size*0.35, cy + size*0.1), # 4
            (cx - size*0.25, cy + size*0.3), # 5
            (cx, cy + size*0.15),            # 6
            (cx + size*0.25, cy + size*0.3), # 7
            (cx + size*0.35, cy + size*0.1), # 8
            (cx + size*0.35, cy - size*0.1), # 9
            (cx + size*0.25, cy - size*0.3), # 10
            (cx + size*0.15, cy - size*0.1), # 11
            (cx - size*0.15, cy - size*0.1), # 12
        ]
        
        # í–‰ì„± ë°°ì¹˜
        planets = self.chart_data.get("planets", {})
        house_contents = {i: [] for i in range(1, 13)}
        
        for name, data in planets.items():
            house_num = data.get("house")
            if house_num:
                abbrev = name[:2].upper() if len(name) <= 3 else name[:3]
                house_contents[house_num].append(abbrev)
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        c.setFont(PDF_FONT_REG, 9)
        for house_num, (x, y) in enumerate(houses_layout, 1):
            content = house_contents.get(house_num, [])
            if content:
                text = ", ".join(content)
                c.drawCentredString(x, y, text)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PDF ìƒì„± í—¬í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_pdf_styles():
    """PDF ìŠ¤íƒ€ì¼ ìƒì„± (Pretendard í°íŠ¸ ì‚¬ìš©)"""
    styles = getSampleStyleSheet()
    
    # í•œê¸€ ì œëª©
    styles.add(ParagraphStyle(
        name='KoreanTitle',
        parent=styles['Title'],
        fontName=PDF_FONT_BOLD,
        fontSize=24,
        leading=30,
        alignment=TA_CENTER,
        spaceAfter=12,
    ))
    
    # í•œê¸€ Heading1
    styles.add(ParagraphStyle(
        name='KoreanHeading1',
        parent=styles['Heading1'],
        fontName=PDF_FONT_BOLD,
        fontSize=16,
        leading=20,
        spaceAfter=8,
        textColor=colors.HexColor('#2C3E50'),
    ))
    
    # í•œê¸€ Heading2
    styles.add(ParagraphStyle(
        name='KoreanHeading2',
        parent=styles['Heading2'],
        fontName=PDF_FONT_BOLD,
        fontSize=13,
        leading=16,
        spaceAfter=6,
        textColor=colors.HexColor('#34495E'),
    ))
    
    # í•œê¸€ ë³¸ë¬¸
    styles.add(ParagraphStyle(
        name='KoreanBody',
        parent=styles['Normal'],
        fontName=PDF_FONT_REG,
        fontSize=10,
        leading=14,
        alignment=TA_JUSTIFY,
        spaceAfter=8,
    ))
    
    # í•œê¸€ ìº¡ì…˜
    styles.add(ParagraphStyle(
        name='KoreanCaption',
        parent=styles['Normal'],
        fontName=PDF_FONT_REG,
        fontSize=9,
        leading=11,
        textColor=colors.grey,
        alignment=TA_CENTER,
    ))
    
    return styles

def parse_markdown_to_flowables(text: str, styles):
    """ê°„ë‹¨í•œ ë§ˆí¬ë‹¤ìš´ íŒŒì‹± â†’ Flowables"""
    flowables = []
    lines = text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            flowables.append(Spacer(1, 0.2*cm))
            continue
        
        # Heading
        if line.startswith('### '):
            clean_line = line[4:].replace('**', '')  # Remove bold markers from headings
            flowables.append(Paragraph(clean_line, styles['KoreanHeading2']))
        elif line.startswith('## '):
            clean_line = line[3:].replace('**', '')
            flowables.append(Paragraph(clean_line, styles['KoreanHeading1']))
        elif line.startswith('# '):
            clean_line = line[2:].replace('**', '')
            flowables.append(Paragraph(clean_line, styles['KoreanTitle']))
        # Section markers
        elif line.startswith('[') and line.endswith(']'):
            flowables.append(Spacer(1, 0.3*cm))
            clean_line = line.replace('**', '')
            flowables.append(Paragraph(f"<b>{clean_line}</b>", styles['KoreanHeading1']))
        # List
        elif line.startswith('- ') or line.startswith('* '):
            clean_line = convert_markdown_bold(line[2:])
            flowables.append(Paragraph('â€¢ ' + clean_line, styles['KoreanBody']))
        else:
            # Regular paragraph
            clean_line = convert_markdown_bold(line)
            flowables.append(Paragraph(clean_line, styles['KoreanBody']))
    
    return flowables

def convert_markdown_bold(text: str) -> str:
    """Convert **bold** to <b>bold</b> safely"""
    import re
    # Replace **text** with <b>text</b>
    # Use regex to properly match pairs
    result = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', text)
    return result

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—”ë“œí¬ì¸íŠ¸: PDF ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/report.pdf")
def generate_pdf(
    year: int = Query(...),
    month: int = Query(...),
    day: int = Query(...),
    hour: float = Query(...),
    lat: float = Query(...),
    lon: float = Query(...),
    house_system: str = Query("W"),  # Vedic uses Whole Sign by default
    include_nodes: int = Query(1),
    include_d9: int = Query(1),
    include_ai: int = Query(1),
    language: str = Query("ko"),
    gender: str = Query("male"),
    ai_cache_key: str = Query(None),
    cache_only: int = Query(0)
):
    """PDF ë¦¬í¬íŠ¸ ìƒì„±"""
    from io import BytesIO
    
    # ì°¨íŠ¸ ê³„ì‚°
    chart = get_chart(year, month, day, hour, lat, lon, house_system, include_nodes, include_d9, gender=gender)
    
    # AI ë¦¬ë”©
    ai_reading = None
    if include_ai:
        if cache_only and ai_cache_key and ai_cache_key in AI_CACHE:
            ai_reading = AI_CACHE[ai_cache_key]
        else:
            ai_reading = get_ai_reading(
                year, month, day, hour, lat, lon,
                house_system, include_nodes, include_d9,
                language, gender, use_cache=1
            )
    
    # PDF ìƒì„±
    with BytesIO() as buffer:
        doc = SimpleDocTemplate(
            buffer,
            pagesize=A4,
            rightMargin=2*cm,
            leftMargin=2*cm,
            topMargin=2*cm,
            bottomMargin=2*cm,
        )

        story = []
        styles = create_pdf_styles()

        # ì œëª©
        title_text = "ë² ë”• ì ì„±í•™ ë¦¬í¬íŠ¸" if language == "ko" else "Vedic Astrology Report"
        story.append(Paragraph(title_text, styles['KoreanTitle']))
        story.append(Spacer(1, 0.5*cm))

        # ì¶œìƒ ì •ë³´
        birth_info = f"""
        <b>ì¶œìƒ ì •ë³´</b><br/>
        ë‚ ì§œ: {year}ë…„ {month}ì›” {day}ì¼<br/>
        ì‹œê°„: {int(hour)}ì‹œ {int((hour % 1) * 60)}ë¶„<br/>
        ìœ„ì¹˜: {lat:.4f}Â°N, {lon:.4f}Â°E
        """ if language == "ko" else f"""
        <b>Birth Information</b><br/>
        Date: {year}-{month:02d}-{day:02d}<br/>
        Time: {int(hour)}:{int((hour % 1) * 60):02d}<br/>
        Location: {lat:.4f}Â°N, {lon:.4f}Â°E
        """
        story.append(Paragraph(birth_info, styles['KoreanBody']))
        story.append(Spacer(1, 0.5*cm))

        # D1 ì°¨íŠ¸
        story.append(Paragraph("D1 ì°¨íŠ¸ (Rasi)" if language == "ko" else "D1 Chart (Rasi)", styles['KoreanHeading1']))
        story.append(SouthIndianChart(chart, width=350, height=350))
        story.append(Spacer(1, 0.5*cm))

        # í–‰ì„± í…Œì´ë¸”
        story.append(Paragraph("í–‰ì„± ë°°ì¹˜" if language == "ko" else "Planetary Positions", styles['KoreanHeading1']))

        planet_data = [["í–‰ì„±", "ë¼ì‹œ", "í•˜ìš°ìŠ¤", "ë‚˜í¬ìƒ¤íŠ¸ë¼", "Dignity"] if language == "ko"
                    else ["Planet", "Sign", "House", "Nakshatra", "Dignity"]]

        for name, data in chart["planets"].items():
            rasi = data["rasi"]["name_kr" if language == "ko" else "name"]
            house = str(data.get("house", "-"))
            nak = data["nakshatra"]["name"]
            dignity = data["features"]["dignity"]
            planet_data.append([name, rasi, house, nak, dignity])

        planet_table = Table(planet_data, colWidths=[3*cm, 4*cm, 2*cm, 4*cm, 3*cm])
        planet_table.setStyle(TableStyle([
            ('FONTNAME', (0, 0), (-1, 0), PDF_FONT_BOLD),
            ('FONTNAME', (0, 1), (-1, -1), PDF_FONT_REG),
            ('FONTSIZE', (0, 0), (-1, -1), 9),
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.black),
            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.lightgrey]),
        ]))
        story.append(planet_table)
        story.append(Spacer(1, 0.5*cm))

        # D9 ì°¨íŠ¸ (ì˜µì…˜)
        if include_d9 and "d9" in chart:
            story.append(PageBreak())
            story.append(Paragraph("D9 ì°¨íŠ¸ (Navamsa)" if language == "ko" else "D9 Chart (Navamsa)", styles['KoreanHeading1']))
            story.append(SouthIndianChart(chart, width=350, height=350, is_d9=True))
            story.append(Spacer(1, 0.5*cm))

        # AI ë¦¬ë”©
        if ai_reading and ai_reading.get("reading"):
            story.append(PageBreak())
            story.append(Paragraph("AI ìƒì„¸ ë¦¬ë”©" if language == "ko" else "AI Detailed Reading", styles['KoreanHeading1']))
            story.append(Spacer(1, 0.3*cm))

            reading_text = ai_reading["reading"]
            flowables = parse_markdown_to_flowables(reading_text, styles)
            story.extend(flowables)

        # PDF ë¹Œë“œ
        doc.build(story)
        pdf_bytes = buffer.getvalue()
    
    return Response(
        content=pdf_bytes,
        media_type="application/pdf",
        headers={"Content-Disposition": "attachment; filename=vedic_report.pdf"}
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# BTR (Birth Time Rectification) ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from fastapi import Body

# BTR ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ
BTR_QUESTIONS_PATH = os.path.join(os.path.dirname(__file__), "btr_questions.json")
BTR_QUESTIONS = {}
try:
    if os.path.exists(BTR_QUESTIONS_PATH):
        with open(BTR_QUESTIONS_PATH, "r", encoding="utf-8") as f:
            BTR_QUESTIONS = json.load(f)
        print(f"[INFO] BTR questions loaded: {BTR_QUESTIONS_PATH}")
    else:
        print(f"[WARN] BTR questions file not found: {BTR_QUESTIONS_PATH}")
except Exception as e:
    print(f"[WARN] BTR questions load failed: {e}")

# BTR ì—”ì§„ import
try:
    from btr_engine import (
        analyze_birth_time,
        refine_time_bracket,
        generate_time_brackets,
        calculate_vimshottari_dasha,
        get_dasha_at_date,
        convert_age_range_to_year_range,
    )
    BTR_ENGINE_AVAILABLE = True
    print("[INFO] BTR engine loaded successfully")
except ImportError as e:
    BTR_ENGINE_AVAILABLE = False
    print(f"[WARN] BTR engine not available: {e}")


def _get_age_group(age: int) -> str:
    """ë‚˜ì´ â†’ ì—°ë ¹ëŒ€ ê·¸ë£¹ í‚¤"""
    if age < 30:
        return "20s"
    elif age < 50:
        return "30s_40s"
    else:
        return "50s_plus"


@app.get("/btr/questions")
def get_btr_questions(
    age: int = Query(..., ge=10, le=120, description="ë‚˜ì´"),
    language: str = Query("ko", description="ì–¸ì–´ (ko/en)")
):
    """
    BTR ì§ˆë¬¸ ë°˜í™˜ (ì—°ë ¹ëŒ€ë³„)

    - ê³µí†µ ì§ˆë¬¸ 10ê°œ + ì—°ë ¹ëŒ€ë³„ ë¶„ê¸° ì§ˆë¬¸ 3ê°œ
    - ì´ 13ê°œ ì§ˆë¬¸ ë°˜í™˜
    """
    if not BTR_QUESTIONS:
        raise HTTPException(status_code=500, detail="BTR ì§ˆë¬¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    common = BTR_QUESTIONS.get("common_questions", [])
    age_group = _get_age_group(age)
    age_specific = BTR_QUESTIONS.get("age_group_questions", {}).get(age_group, [])

    all_questions = common + age_specific

    # ì–¸ì–´ë³„ í…ìŠ¤íŠ¸ ì„ íƒ
    formatted = []
    for q in all_questions:
        text_key = "text_ko" if language == "ko" else "text_en"
        options_formatted = {}
        for opt_key, opt_val in q.get("options", {}).items():
            opt_text_key = "text_ko" if language == "ko" else "text_en"
            options_formatted[opt_key] = opt_val.get(opt_text_key, opt_val.get("text_ko", ""))

        formatted.append({
            "id": q["id"],
            "text": q.get(text_key, q.get("text_ko", "")),
            "text_ko": q.get("text_ko", ""),
            "text_en": q.get("text_en", ""),
            "type": q["type"],
            "options": options_formatted,
            "event_type": q.get("event_type", ""),
            "weight": q.get("weight", 1.0),
            "dasha_lords": q.get("dasha_lords", []),
            "house_triggers": q.get("house_triggers", []),
        })

    return {
        "age": age,
        "age_group": age_group,
        "language": language,
        "total_questions": len(formatted),
        "questions": formatted,
    }


@app.post("/btr/analyze")
def analyze_btr(request: BTRAnalyzeRequest):
    """
    BTR ë¶„ì„ ì‹¤í–‰

    Request Body:
    {
        "year": 1994,
        "month": 12,
        "day": 18,
        "lat": 37.5665,
        "lon": 126.978,
        "events": [
            {
                "type": "marriage",
                "year": 2015,
                "month": 6,
                "weight": 0.8,
                "dasha_lords": ["Venus", "Jupiter"],
                "house_triggers": [7]
            }
        ]
    }

    Returns:
        Top 3 í›„ë³´ ì‹œê°„ëŒ€ + ì‹ ë¢°ë„
    """
    if not BTR_ENGINE_AVAILABLE:
        raise HTTPException(status_code=500, detail="BTR ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    if not request.events:
        raise HTTPException(status_code=400, detail="ì´ë²¤íŠ¸ê°€ í•˜ë‚˜ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")

    # ë¯¸ë˜ ì´ë²¤íŠ¸ ê²€ì¦ (precision_level ë³„)
    current_year = datetime.now().year
    for ev in request.events:
        if ev.precision_level == "exact":
            if ev.year is not None and ev.year > current_year:
                raise HTTPException(
                    status_code=400,
                    detail=f"ë¯¸ë˜ ì´ë²¤íŠ¸ëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ev.year}"
                )
        elif ev.precision_level == "range":
            if ev.age_range is None:
                raise HTTPException(
                    status_code=400,
                    detail="range ì´ë²¤íŠ¸ëŠ” age_rangeê°€ í•„ìš”í•©ë‹ˆë‹¤."
                )
            _, upper_year = convert_age_range_to_year_range(request.year, ev.age_range)
            if upper_year > current_year:
                raise HTTPException(
                    status_code=400,
                    detail=f"ë¯¸ë˜ ë²”ìœ„ ì´ë²¤íŠ¸ëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {upper_year}"
                )
        elif ev.precision_level == "unknown":
            # unknownì€ ì—°ë„ ê²€ì¦ì„ ìƒëµ
            continue

    try:
        birth_date = {"year": request.year, "month": request.month, "day": request.day}

        # Pydantic ëª¨ë¸ì„ dictë¡œ ë³€í™˜
        events_dict = [ev.model_dump() for ev in request.events]

        candidates = analyze_birth_time(
            birth_date=birth_date,
            events=events_dict,
            lat=request.lat,
            lon=request.lon,
            num_brackets=8,
            top_n=3,
        )

        return {
            "status": "ok",
            "birth_date": birth_date,
            "lat": request.lat,
            "lon": request.lon,
            "total_events": len(request.events),
            "candidates": candidates,
        }

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"BTR ë¶„ì„ ì˜¤ë¥˜: {str(e)}")


@app.post("/btr/refine")
def refine_btr(request: BTRRefineRequest):
    """
    ì„ íƒëœ ë¸Œë˜í‚· 2ì°¨ ì •ë°€í™” (30ë¶„ ë‹¨ìœ„)

    Returns:
        ì„¸ë¶„í™”ëœ 6ê°œ í›„ë³´
    """
    if not BTR_ENGINE_AVAILABLE:
        raise HTTPException(status_code=500, detail="BTR ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    if not request.events:
        raise HTTPException(status_code=400, detail="ì´ë²¤íŠ¸ê°€ í•˜ë‚˜ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")

    try:
        birth_date = {"year": request.year, "month": request.month, "day": request.day}
        bracket = {"start": request.bracket_start, "end": request.bracket_end}

        # Pydantic ëª¨ë¸ì„ dictë¡œ ë³€í™˜
        events_dict = [ev.model_dump() for ev in request.events]

        refined = refine_time_bracket(
            date=birth_date,
            bracket=bracket,
            events=events_dict,
            lat=request.lat,
            lon=request.lon,
            sub_intervals=6,
        )

        return {
            "status": "ok",
            "birth_date": birth_date,
            "original_bracket": bracket,
            "refined_candidates": refined,
        }

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"BTR ì •ë°€í™” ì˜¤ë¥˜: {str(e)}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import uvicorn
    init_fonts()
    uvicorn.run(app, host="0.0.0.0", port=8000)
