#!/usr/bin/env python3
"""
????????????????????????(FastAPI)
- ???????????????? Swiss Ephemeris + Lahiri Ayanamsa
- AI ??????? OpenAI GPT
- PDF ?????????? ReportLab (Pretendard ????????????????
"""

import os
import json
import math
import base64
import logging
import asyncio
from pathlib import Path
from enum import Enum
from datetime import datetime
from typing import Optional, Any, Literal, Tuple, Dict, List

# Structural engine import via the backend package to keep resolution stable
# when running `uvicorn backend.main:app` from any working directory.
from backend.astro_engine import build_structural_summary
from backend.report_engine import build_report_payload, REPORT_CHAPTERS, build_gpt_user_content
from backend.prompts import SYSTEM_PROMPT, USER_PROMPT_TEMPLATE
from backend.cache_manager import cache
from backend.swe_config import initialize_swe_context

try:
    import swisseph as swe
except Exception as e:
    raise RuntimeError("Swiss Ephemeris not properly installed in container") from e
import pytz
try:
    from timezonefinder import TimezoneFinder
except Exception:
    TimezoneFinder = None  # type: ignore[assignment]
from openai import AsyncOpenAI

from fastapi import FastAPI, Query, Response, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from pydantic import AliasChoices, BaseModel, ConfigDict, Field, model_validator

# ReportLab PDF ??????
from reportlab.lib import colors
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import cm
from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY
from reportlab.platypus import (
    SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle,
    PageBreak, KeepTogether, Flowable
)
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s ??%(message)s",
)

logger = logging.getLogger("vedic_ai")

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# ???????????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# Pretendard ?????????????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
FONT_DIR = os.path.join(os.path.dirname(__file__), 'fonts')
FONT_REGULAR = os.path.join(FONT_DIR, 'Pretendard-Regular.ttf')
FONT_BOLD = os.path.join(FONT_DIR, 'Pretendard-Bold.ttf')

KOREAN_FONT_AVAILABLE = False
PDF_FONT_REG = 'Helvetica'
PDF_FONT_BOLD = 'Helvetica-Bold'
PDF_FONT_MONO = 'Courier'


def init_fonts() -> None:
    """PDF ?????????????????????????????????????? ???????????????????????????????????????????????"""
    global KOREAN_FONT_AVAILABLE, PDF_FONT_REG, PDF_FONT_BOLD, PDF_FONT_MONO

    KOREAN_FONT_AVAILABLE = False
    PDF_FONT_REG = 'Helvetica'
    PDF_FONT_BOLD = 'Helvetica-Bold'
    PDF_FONT_MONO = 'Courier'

    nanum_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'

    try:
        if os.path.exists(FONT_REGULAR):
            pdfmetrics.registerFont(TTFont('Pretendard', FONT_REGULAR))
            if os.path.exists(FONT_BOLD):
                pdfmetrics.registerFont(TTFont('Pretendard-Bold', FONT_BOLD))
                PDF_FONT_BOLD = 'Pretendard-Bold'
            else:
                PDF_FONT_BOLD = 'Helvetica-Bold'
                logger.warning(
                    'Pretendard-Bold.ttf not found; using system bold fallback Helvetica-Bold.'
                )

            KOREAN_FONT_AVAILABLE = True
            PDF_FONT_REG = 'Pretendard'
            PDF_FONT_MONO = 'Pretendard'
            logger.info('Pretendard font loaded.')
            return

        if os.path.exists(nanum_path):
            pdfmetrics.registerFont(TTFont('NanumGothic', nanum_path))
            KOREAN_FONT_AVAILABLE = True
            PDF_FONT_REG = 'NanumGothic'
            PDF_FONT_BOLD = 'NanumGothic'
            PDF_FONT_MONO = 'NanumGothic'
            logger.info('NanumGothic font loaded from system.')
            return

        raise FileNotFoundError(
            f'Neither Pretendard ({FONT_REGULAR}) nor NanumGothic ({nanum_path}) was found.'
        )
    except Exception as e:
        logger.error(f'Font initialization failed: {e}')
        raise RuntimeError('No valid Korean font available in production container.') from e


init_fonts()

app = FastAPI(title="Vedic AI Backend")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# OpenAI ?????????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
async_client = None
if OPENAI_API_KEY:
    try:
        async_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
    except Exception as e:
        logger.warning(f"OpenAI client initialization failed: {e}")

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# AI ?????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
AI_CACHE_TTL = 1800  # 30??
CHART_MAX_CONCURRENCY = max(1, int(os.getenv("CHART_MAX_CONCURRENCY", "8")))
CHART_CALC_SEMAPHORE = asyncio.Semaphore(CHART_MAX_CONCURRENCY)

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# ????????????????????????????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
PROJECT_ROOT = Path(__file__).resolve().parent.parent
ASSET_ROOT = Path(os.getenv("ASSET_PATH", PROJECT_ROOT / "assets")).expanduser()
INTERPRETATION_FILE = str(
    Path(
        os.getenv(
            "INTERPRETATION_FILE",
            ASSET_ROOT / "data" / "interpretations.kr_final.json",
        )
    ).expanduser().resolve()
)
INTERPRETATIONS_DATA: dict[str, Any] | None = None
INTERPRETATIONS_KO: dict[str, Any] = {}
INTERPRETATIONS_ATOMIC_KO: dict[str, Any] = {}
INTERPRETATIONS_LOAD_ERROR: str | None = None

try:
    with open(INTERPRETATION_FILE, "r", encoding="utf-8") as f:
        INTERPRETATIONS_DATA = json.load(f)
    INTERPRETATIONS_KO = (INTERPRETATIONS_DATA.get("ko") or {})
    INTERPRETATIONS_ATOMIC_KO = INTERPRETATIONS_KO.get("atomic") or {}
    if not isinstance(INTERPRETATIONS_ATOMIC_KO, dict):
        INTERPRETATIONS_LOAD_ERROR = "ko.atomic is not a dictionary"
        INTERPRETATIONS_ATOMIC_KO = {}
except Exception as e:
    INTERPRETATIONS_LOAD_ERROR = str(e)
    logger.warning(f"interpretations file load failed: {e} (path={INTERPRETATION_FILE})")

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# Swiss Ephemeris ?????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
SWE_CONTEXT_STATUS = initialize_swe_context(logger)

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# ???????? ??????? ??????? ??????????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
PLANET_IDS = {
    "Sun": swe.SUN,
    "Moon": swe.MOON,
    "Mars": swe.MARS,
    "Mercury": swe.MERCURY,
    "Jupiter": swe.JUPITER,
    "Venus": swe.VENUS,
    "Saturn": swe.SATURN,
}
RAHU_KETU_IDS = {
    "Rahu": swe.MEAN_NODE,
    "Ketu": swe.MEAN_NODE,
}

RASI_NAMES = [
    "Aries", "Taurus", "Gemini", "Cancer", "Leo", "Virgo",
    "Libra", "Scorpio", "Sagittarius", "Capricorn", "Aquarius", "Pisces"
]
RASI_NAMES_KR = [
    "Aries", "Taurus", "Gemini", "Cancer", "Leo", "Virgo",
    "Libra", "Scorpio", "Sagittarius", "Capricorn", "Aquarius", "Pisces",
]
NAKSHATRA_NAMES = [
    "Ashwini", "Bharani", "Krittika", "Rohini", "Mrigashira", "Ardra",
    "Punarvasu", "Pushya", "Ashlesha", "Magha", "Purva Phalguni", "Uttara Phalguni",
    "Hasta", "Chitra", "Swati", "Vishakha", "Anuradha", "Jyeshtha",
    "Mula", "Purva Ashadha", "Uttara Ashadha", "Shravana", "Dhanishta", "Shatabhisha",
    "Purva Bhadrapada", "Uttara Bhadrapada", "Revati"
]

HOUSE_SYSTEMS = {
    "P": "Placidus",
    "W": "Whole Sign",
}

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# Pydantic ?????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
class EventType(str, Enum):
    career_change = "career_change"
    relationship = "relationship"
    relocation = "relocation"
    health = "health"
    finance = "finance"
    other = "other"


class BTREvent(BaseModel):
    model_config = ConfigDict(extra="ignore")
    event_type: EventType = Field(
        ...,
        description="Event type",
        validation_alias=AliasChoices("event_type", "type"),
    )
    precision_level: Literal["exact", "range", "unknown"] = Field(
        "exact",
        description="Precision level (exact | range | unknown)",
    )
    year: Optional[int] = Field(None, description="Event year")
    age_range: Optional[Tuple[int, int]] = Field(None, description="Event age range (start, end)")
    other_label: Optional[str] = Field(None, description="Custom event label")
    weight: Optional[float] = Field(1.0, description="Event weight")
    dasha_lords: Optional[list[str]] = Field(default_factory=list, description="Dasha lords")
    house_triggers: Optional[list[int]] = Field(default_factory=list, description="House triggers")

    @model_validator(mode="after")
    def validate_precision_payload(self) -> "BTREvent":
        """precision_level????????????????????????????????????????????????"""
        if self.event_type == EventType.other and not self.other_label:
            raise ValueError("event_type='other' ?????????other_label?? ???????????????")

        if self.precision_level == "exact":
            if self.year is None:
                raise ValueError("precision_level='exact' ?????????year?????????????????")
            if self.age_range is not None:
                raise ValueError("precision_level='exact' ?????????age_range???????????????????????.")

        elif self.precision_level == "range":
            if self.age_range is None:
                raise ValueError("precision_level='range' ?????????age_range?????????????????")
            start_age, end_age = self.age_range
            if start_age < 0 or end_age < 0:
                raise ValueError("age_range ??????? 0 ???????????????????????")
            if start_age > end_age:
                raise ValueError("age_range ?????????????? ?????????????????????????????????????.")
            if self.year is not None:
                raise ValueError("precision_level='range' ?????????year???????????????????????.")

        elif self.precision_level == "unknown":
            if self.year is not None or self.age_range is not None:
                raise ValueError("precision_level='unknown' ?????????year/age_range??????????????????????????")

        return self


def validate_btr_events(events: List[BTREvent]) -> None:
    """
    Enforce:
    - At least one event must have precision_level != "unknown"
    - Reject empty list
    - Raise HTTPException(400, detail="Please choose a timing for at least one event.")
    """
    if len(events) == 0 or all(e.precision_level == "unknown" for e in events):
        raise HTTPException(status_code=400, detail="Please choose a timing for at least one event.")

class BTRAnalyzeRequest(BaseModel):
    year: int = Field(..., description="Birth year")
    month: int = Field(..., ge=1, le=12, description="Birth month")
    day: int = Field(..., ge=1, le=31, description="Birth day")
    lat: float = Field(..., ge=-90, le=90, description="Latitude")
    lon: float = Field(..., ge=-180, le=180, description="Longitude")
    timezone: Optional[float] = Field(None, description="UTC offset hours")
    events: list[BTREvent] = Field(..., description="Event list")
    tune_mode: bool = Field(False, description="Enable tuning mode")

class BTRRefineRequest(BaseModel):
    year: int = Field(..., description="Birth year")
    month: int = Field(..., ge=1, le=12, description="Birth month")
    day: int = Field(..., ge=1, le=31, description="Birth day")
    lat: float = Field(..., ge=-90, le=90, description="Latitude")
    lon: float = Field(..., ge=-180, le=180, description="Longitude")
    bracket_start: float = Field(..., description="Bracket start hour")
    bracket_end: float = Field(..., description="Bracket end hour")
    events: list[BTREvent] = Field(..., description="Event list")
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# ?????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
def normalize_360(deg: float) -> float:
    """Normalize angle into [0, 360)."""
    while deg < 0:
        deg += 360
    while deg >= 360:
        deg -= 360
    return deg

def get_rasi_index(lon: float) -> int:
    """Return rasi index in range 0..11."""
    return int(lon / 30.0) % 12

def get_nakshatra_info(lon: float):
    """???????????????????????(0~26, pada 1~4)"""
    nak_idx = int(lon / (360.0 / 27))
    nak_name = NAKSHATRA_NAMES[nak_idx]
    deg_in_nak = lon - (nak_idx * (360.0 / 27))
    pada = int(deg_in_nak / (360.0 / 27 / 4)) + 1
    return {"index": nak_idx, "name": nak_name, "pada": pada}

def get_dignity(planet_name: str, rasi_idx: int, lon: float) -> str:
    """?????????Dignity ?????(Own/Exalted/Debilitated/Neutral)"""
    rules = {
        "Sun": {"own": [4], "exalted": [0], "debilitated": [6]},
        "Moon": {"own": [3], "exalted": [1], "debilitated": [7]},
        "Mars": {"own": [0, 7], "exalted": [9], "debilitated": [3]},
        "Mercury": {"own": [2, 5], "exalted": [5], "debilitated": [11]},
        "Jupiter": {"own": [8, 11], "exalted": [3], "debilitated": [9]},
        "Venus": {"own": [1, 6], "exalted": [11], "debilitated": [5]},
        "Saturn": {"own": [9, 10], "exalted": [6], "debilitated": [0]},
    }
    r = rules.get(planet_name, {})
    if rasi_idx in r.get("own", []):
        return "Own"
    if rasi_idx in r.get("exalted", []):
        return "Exalted"
    if rasi_idx in r.get("debilitated", []):
        return "Debilitated"
    return "Neutral"

def is_combust(planet_name: str, planet_lon: float, sun_lon: float) -> bool:
    """Determine combust status."""
    if planet_name == "Sun":
        return False
    thresholds = {
        "Moon": 12, "Mars": 17, "Mercury": 14,
        "Jupiter": 11, "Venus": 10, "Saturn": 15
    }
    threshold = thresholds.get(planet_name, 10)
    diff = abs(normalize_360(planet_lon - sun_lon))
    if diff > 180:
        diff = 360 - diff
    return diff < threshold

def resolve_timezone_offset(
    year: int,
    month: int,
    day: int,
    lat: float,
    lon: float,
    timezone: Optional[float] = None,
) -> float:
    """Resolve UTC offset from coordinates or explicit timezone input."""
    if timezone is not None:
        return float(timezone)

    if TimezoneFinder is None:
        raise HTTPException(
            status_code=400,
            detail=(
                "Timezone auto-resolution is unavailable. "
                "Please provide timezone as UTC offset hours (e.g. 9.0 for KST)."
            ),
        )

    tf = TimezoneFinder()
    tz_name = tf.timezone_at(lat=lat, lng=lon)
    if not tz_name:
        raise HTTPException(
            status_code=400,
            detail=(
                f"Unable to determine timezone from coordinates lat={lat}, lon={lon}. "
                "Please provide timezone as UTC offset hours."
            ),
        )

    try:
        tz = pytz.timezone(tz_name)
        sample_dt = datetime(year, month, day)
        tz_offset = tz.utcoffset(sample_dt).total_seconds() / 3600.0
    except Exception as exc:
        raise HTTPException(
            status_code=400,
            detail=(
                f"Failed to resolve timezone offset for timezone '{tz_name}'. "
                "Please provide timezone as UTC offset hours."
            ),
        ) from exc

    logger.debug(f"Timezone: {tz_name}, tz_offset={tz_offset}")
    return tz_offset


def compute_julian_day(
    year: int,
    month: int,
    day: int,
    hour_frac: float,
    lat: float,
    lon: float,
    tz_offset: float,
) -> float:
    """???????????????????????(?????????????- UTC ?????????."""
    del lat, lon
    jd = swe.julday(year, month, day, hour_frac - tz_offset)
    logger.debug(f"Julian day: {jd}")
    return jd


def compute_julian_day_legacy(
    year: int,
    month: int,
    day: int,
    hour_frac: float,
    lat: float,
    lon: float,
    timezone: Optional[float] = None,
) -> float:
    """?????????????????????????????????"""
    tz_offset = resolve_timezone_offset(year, month, day, lat, lon, timezone=timezone)
    return compute_julian_day(year, month, day, hour_frac, lat, lon, tz_offset)

def extract_atomic_interpretation_text(entry: Any) -> str | None:
    """Extract interpretation text from dict or string entry."""
    if isinstance(entry, dict):
        text = entry.get("text")
        if isinstance(text, str) and text.strip():
            return text.strip()
    elif isinstance(entry, str) and entry.strip():
        return entry.strip()
    return None


def build_atomic_keys_from_chart(chart: dict) -> list[str]:
    """?????????????atomic ?????????? ?????????????"""
    keys: list[str] = []

    asc_sign = (((chart.get("houses") or {}).get("ascendant") or {}).get("rasi") or {}).get("name")
    if isinstance(asc_sign, str) and asc_sign:
        keys.append(f"asc:{asc_sign}")

    for planet_name, pdata in (chart.get("planets") or {}).items():
        sign_name = ((pdata.get("rasi") or {}).get("name"))
        if isinstance(sign_name, str) and sign_name:
            keys.append(f"ps:{planet_name}:{sign_name}")

        house_num = pdata.get("house")
        if isinstance(house_num, int):
            keys.append(f"ph:{planet_name}:{house_num}")

    # ???????? ???????????????????
    return list(dict.fromkeys(keys))


def yoga_name_to_key(yoga_name: str) -> str:
    """Convert yoga display name to interpretation key."""
    cleaned = yoga_name.replace("Yoga", "").replace("yoga", "").strip()
    cleaned = ''.join(ch for ch in cleaned if ch.isalnum())
    return f"yoga:{cleaned}" if cleaned else ""


def collect_interpretation_context(chart: dict) -> tuple[list[str], list[str], dict[str, int]]:
    """Collect interpretation context texts from chart signals."""
    keys: list[str] = []
    texts: list[str] = []
    section_counts = {"atomic": 0, "lagna_lord": 0, "yogas": 0, "patterns": 0}

    ko_data = INTERPRETATIONS_KO if isinstance(INTERPRETATIONS_KO, dict) else {}

    # 1) atomic: asc / planet-sign / planet-house
    atomic = ko_data.get("atomic") or {}
    if isinstance(atomic, dict):
        for key in build_atomic_keys_from_chart(chart):
            text = extract_atomic_interpretation_text(atomic.get(key))
            if text:
                keys.append(key)
                texts.append(text)
                section_counts["atomic"] += 1

    # 2) yogas: chart.features.yogas hit ??????????????????
    yogas = ko_data.get("yogas") or {}
    if isinstance(yogas, dict):
        for yoga in (((chart.get("features") or {}).get("yogas")) or []):
            if not isinstance(yoga, dict) or not yoga.get("hit"):
                continue
            yoga_name = yoga.get("name")
            if not isinstance(yoga_name, str):
                continue
            yoga_key = yoga_name_to_key(yoga_name)
            if not yoga_key:
                continue
            text = extract_atomic_interpretation_text(yogas.get(yoga_key))
            if text:
                keys.append(yoga_key)
                texts.append(text)
                section_counts["yogas"] += 1

    # 3) patterns: chart.features.patterns?????? ?????????????????????(????????????
    patterns = ko_data.get("patterns") or {}
    if isinstance(patterns, dict):
        for pat in (((chart.get("features") or {}).get("patterns")) or []):
            if isinstance(pat, str):
                pat_key = pat if pat.startswith("pat:") else f"pat:{pat}"
            elif isinstance(pat, dict):
                raw_key = pat.get("id") or pat.get("key") or pat.get("name")
                if not isinstance(raw_key, str):
                    continue
                pat_key = raw_key if raw_key.startswith("pat:") else f"pat:{raw_key}"
            else:
                continue
            text = extract_atomic_interpretation_text(patterns.get(pat_key))
            if text:
                keys.append(pat_key)
                texts.append(text)
                section_counts["patterns"] += 1

    # 4) lagna_lord: chart.features.lagna_lord_keys?????? ???????????????????????????
    lagna_lord = ko_data.get("lagna_lord") or {}
    if isinstance(lagna_lord, dict):
        for ll_key in (((chart.get("features") or {}).get("lagna_lord_keys")) or []):
            if not isinstance(ll_key, str):
                continue
            key = ll_key if ll_key.startswith("ll:") else f"ll:{ll_key}"
            text = extract_atomic_interpretation_text(lagna_lord.get(key))
            if text:
                keys.append(key)
                texts.append(text)
                section_counts["lagna_lord"] += 1

    dedup_keys = list(dict.fromkeys(keys))
    dedup_texts = list(dict.fromkeys(texts))
    return dedup_keys, dedup_texts, section_counts

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# ??????????? Health Check
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
@app.get("/health")
def health():
    return {
        "status": "ok",
        "openai_configured": bool(async_client),
        "model": OPENAI_MODEL,
        "ai_cache_items": len(cache),
        "ai_cache_ttl_sec": AI_CACHE_TTL,
        "korean_font": KOREAN_FONT_AVAILABLE,
        "pdf_font_reg": PDF_FONT_REG,
        "pdf_font_bold": PDF_FONT_BOLD,
        "pdf_font_mono": PDF_FONT_MONO,
        "ephemeris_path": SWE_CONTEXT_STATUS.get("ephemeris_path"),
        "ephemeris_backend": SWE_CONTEXT_STATUS.get("ephemeris_backend"),
        "ephemeris_verified": SWE_CONTEXT_STATUS.get("ephemeris_verified", False),
        "sidereal_mode": SWE_CONTEXT_STATUS.get("sidereal_mode"),
    }

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# ??????????? Presets (??????????????????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
@app.get("/presets")
def get_presets():
    return {
        "presets": [
            {
                "id": "my_birth",
                "label": "My Birth Info",
                "year": 1994,
                "month": 12,
                "day": 18,
                "hour": 23.75,
                "lat": 37.5665,
                "lon": 126.9780
            }
        ]
    }

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# ??????????? ????????????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
def get_chart(
    year: int = Query(...),
    month: int = Query(...),
    day: int = Query(...),
    hour: float = Query(...),
    lat: float = Query(..., ge=-90, le=90),
    lon: float = Query(..., ge=-180, le=180),
    house_system: str = Query("W"),  # Vedic uses Whole Sign by default
    include_nodes: int = Query(1),
    include_d9: int = Query(0),
    include_interpretation: int = Query(0),
    gender: str = Query("male"),
    timezone: Optional[float] = Query(None),
):
    """Compute Vedic chart payload."""
    # ?????????????? ?????????????? ???????????????????????
    logger.debug("Received parameters:")
    logger.debug(f"year={year}, month={month}, day={day}, hour={hour}")
    logger.debug(f"lat={lat}, lon={lon}")
    logger.debug(f"house_system={house_system}, gender={gender}")

    try:
        jd = compute_julian_day_legacy(year, month, day, hour, lat, lon, timezone=timezone)
        
        # ??????????????
        planets = {}
        sun_lon = None

        for name, pid in PLANET_IDS.items():
            res, _ = swe.calc_ut(jd, pid, swe.FLG_SIDEREAL)
            p_lon = normalize_360(res[0])
            if name == "Sun":
                sun_lon = p_lon

            rasi_idx = get_rasi_index(p_lon)
            nak = get_nakshatra_info(p_lon)
            deg_in_sign = p_lon - (rasi_idx * 30)

            planets[name] = {
                "longitude": round(p_lon, 6),
                "rasi": {
                    "index": rasi_idx,
                    "name": RASI_NAMES[rasi_idx],
                    "name_kr": RASI_NAMES_KR[rasi_idx],
                    "deg_in_sign": round(deg_in_sign, 2)
                },
                "nakshatra": nak,
                "features": {
                    "dignity": get_dignity(name, rasi_idx, p_lon),
                    "retrograde": res[3] < 0,
                    "combust": False  # ???????????????
                }
            }
        
        # Combustion ?????
        if sun_lon is not None:
            for name in planets:
                if name != "Sun":
                    planets[name]["features"]["combust"] = is_combust(
                        name, planets[name]["longitude"], sun_lon
                    )
        
        # Rahu/Ketu
        if include_nodes:
            rahu_res, _ = swe.calc_ut(jd, swe.MEAN_NODE, swe.FLG_SIDEREAL)
            rahu_lon = normalize_360(rahu_res[0])
            ketu_lon = normalize_360(rahu_lon + 180)

            for name, p_lon in [("Rahu", rahu_lon), ("Ketu", ketu_lon)]:
                rasi_idx = get_rasi_index(p_lon)
                nak = get_nakshatra_info(p_lon)
                deg_in_sign = p_lon - (rasi_idx * 30)
                
                planets[name] = {
                    "longitude": round(p_lon, 6),
                    "rasi": {
                        "index": rasi_idx,
                        "name": RASI_NAMES[rasi_idx],
                        "name_kr": RASI_NAMES_KR[rasi_idx],
                        "deg_in_sign": round(deg_in_sign, 2)
                    },
                    "nakshatra": nak,
                    "features": {
                        "dignity": "Shadow",
                        "retrograde": True,
                        "combust": False
                    }
                }
        
        # ??????????????(Placidus/Whole Sign)
        # Swiss Ephemeris houses()??Tropical ?????????????????????????Ayanamsa???????????Sidereal??????????
        ayanamsa = swe.get_ayanamsa_ut(jd)

        houses = {}
        if house_system == "P":
            # swe.houses() expects DEGREES, not radians!
            logger.debug(f"INPUT Lat/Lon (degrees): {lat}, {lon}")
            cusps, ascmc = swe.houses(jd, lat, lon, b'P')
            asc_tropical = ascmc[0]

            # ?????????????? Houses ????????????????
            logger.debug(f"Ayanamsa: {ayanamsa}")
            logger.debug(f"Tropical Ascendant: {asc_tropical}")
            logger.debug(f"Sidereal Ascendant: {normalize_360(asc_tropical - ayanamsa)}")

            # Tropical ??????????????????Ayanamsa???????????Sidereal ??????????????????
            asc_lon = normalize_360(ascmc[0] - ayanamsa)
            for i in range(12):
                # ????????????????????????Sidereal??????????
                cusp_lon = normalize_360(cusps[i + 1] - ayanamsa)
                rasi_idx = get_rasi_index(cusp_lon)
                houses[f"house_{i+1}"] = {
                    "cusp_longitude": round(cusp_lon, 6),
                    "rasi": RASI_NAMES[rasi_idx]
                }
        else:  # Whole Sign
            # swe.houses() expects DEGREES, not radians!
            cusps, ascmc = swe.houses(jd, lat, lon, b'W')
            asc_tropical = ascmc[0]
            # Tropical ??????????????????Ayanamsa???????????Sidereal ??????????????????
            asc_lon = normalize_360(ascmc[0] - ayanamsa)
            asc_rasi = get_rasi_index(asc_lon)
            for i in range(12):
                rasi_idx = (asc_rasi + i) % 12
                houses[f"house_{i+1}"] = {
                    "cusp_longitude": round((rasi_idx * 30), 6),
                    "rasi": RASI_NAMES[rasi_idx]
                }
        
        # Ascendant
        asc_rasi_idx = get_rasi_index(asc_lon)
        houses["ascendant"] = {
            "longitude": round(asc_lon, 6),
            "rasi": {
                "index": asc_rasi_idx,
                "name": RASI_NAMES[asc_rasi_idx],
                "name_kr": RASI_NAMES_KR[asc_rasi_idx]
            }
        }
        
        # ??????????????????????
        for name, data in planets.items():
            p_lon = data["longitude"]
            if house_system == "P":
                for i in range(12):
                    c1 = houses[f"house_{i+1}"]["cusp_longitude"]
                    c2 = houses[f"house_{(i+1)%12 + 1}"]["cusp_longitude"] if i < 11 else houses["house_1"]["cusp_longitude"]
                    if c1 <= c2:
                        if c1 <= p_lon < c2:
                            data["house"] = i + 1
                            break
                    else:
                        if p_lon >= c1 or p_lon < c2:
                            data["house"] = i + 1
                            break
            else:  # Whole Sign
                p_rasi = data["rasi"]["index"]
                data["house"] = ((p_rasi - asc_rasi_idx) % 12) + 1
        
        # D9 (Navamsa) - ????????????????
        d9_data = None
        if include_d9:
            d9_planets = {}
            for name, data in planets.items():
                p_lon = data["longitude"]
                d9_lon = (p_lon * 9) % 360
                d9_rasi_idx = get_rasi_index(d9_lon)
                d9_planets[name] = {
                    "rasi": RASI_NAMES[d9_rasi_idx],
                    "rasi_kr": RASI_NAMES_KR[d9_rasi_idx]
                }
            d9_data = {"planets": d9_planets}
        
        # ??? (????????????????
        yogas = []
        # Budha-Aditya Yoga
        if "Mercury" in planets and "Sun" in planets:
            merc_house = planets["Mercury"].get("house", 0)
            sun_house = planets["Sun"].get("house", 0)
            if merc_house == sun_house:
                yogas.append({
                    "name": "Budha-Aditya Yoga",
                    "hit": True,
                    "note": "Sun and Mercury conjunct"
                })
        
        result = {
            "input": {
                "year": year, "month": month, "day": day, "hour": hour,
                "lat": lat, "lon": lon,
                "house_system": house_system,
                "include_nodes": bool(include_nodes),
                "include_d9": bool(include_d9),
                "gender": gender
            },
            "julian_day": jd,
            "planets": planets,
            "houses": houses,
            "features": {
                "yogas": yogas
            },
            "debug": {
                "ayanamsa": round(ayanamsa, 4),
                "asc_tropical": round(asc_tropical, 4),
                "asc_sidereal": round(asc_lon, 4)
            }
        }
        
        if d9_data:
            result["d9"] = d9_data
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/chart")
async def get_chart_endpoint(
    year: int = Query(...),
    month: int = Query(...),
    day: int = Query(...),
    hour: float = Query(...),
    lat: float = Query(..., ge=-90, le=90),
    lon: float = Query(..., ge=-180, le=180),
    house_system: str = Query("W"),
    include_nodes: int = Query(1),
    include_d9: int = Query(0),
    include_interpretation: int = Query(0),
    gender: str = Query("male"),
    timezone: Optional[float] = Query(None),
):
    del include_interpretation
    # Bound heavy Swiss Ephemeris work under explicit concurrency control.
    async with CHART_CALC_SEMAPHORE:
        return await asyncio.to_thread(
            get_chart,
            year=year,
            month=month,
            day=day,
            hour=hour,
            lat=lat,
            lon=lon,
            house_system=house_system,
            include_nodes=include_nodes,
            include_d9=include_d9,
            gender=gender,
            timezone=timezone,
        )

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# Rectified bridge helpers
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
def build_rectified_chart_payload(
    btr_candidate: dict,
    birth_date: dict,
    latitude: float,
    longitude: float,
    timezone: Optional[float],
) -> dict:
    """Build deterministic chart payload from a rectified BTR candidate."""
    mid_hour = float(btr_candidate.get("mid_hour", 0.0))
    return get_chart(
        year=int(birth_date["year"]),
        month=int(birth_date["month"]),
        day=int(birth_date["day"]),
        hour=mid_hour,
        lat=float(latitude),
        lon=float(longitude),
        house_system="W",
        include_nodes=1,
        include_d9=1,
        include_interpretation=0,
        gender="male",
        timezone=timezone,
    )


def build_rectified_structural_summary(
    btr_candidates: list,
    birth_date: dict,
    latitude: float,
    longitude: float,
    timezone: Optional[float],
) -> dict:
    """Bridge top BTR candidate to deterministic structural summary."""
    if not btr_candidates:
        raise HTTPException(status_code=400, detail="No BTR candidates available")

    top_candidate = btr_candidates[0]
    chart_data = build_rectified_chart_payload(
        btr_candidate=top_candidate,
        birth_date=birth_date,
        latitude=latitude,
        longitude=longitude,
        timezone=timezone,
    )
    structural_summary = build_structural_summary(chart_data)

    return {
        "rectified_time_range": top_candidate.get("time_range", ""),
        "rectified_probability": float(top_candidate.get("probability", 0.0)),
        "rectified_confidence": float(top_candidate.get("confidence", 0.0)),
        "structural_summary": structural_summary,
    }


def build_ai_psychological_input(
    rectified_structural_summary: dict,
) -> dict:
    """Build compact AI-safe signal payload (no raw longitude/degree data)."""
    def _json_safe(value):
        if isinstance(value, dict):
            return {str(k): _json_safe(v) for k, v in value.items()}
        if isinstance(value, list):
            return [_json_safe(v) for v in value]
        if isinstance(value, tuple):
            return [_json_safe(v) for v in value]
        if isinstance(value, (str, int, float, bool)) or value is None:
            return value
        if hasattr(value, "item"):
            try:
                return _json_safe(value.item())
            except Exception:
                return str(value)
        return str(value)

    source = rectified_structural_summary.get("structural_summary", {}) or {}
    allowed_keys = [
        "planet_power_ranking",
        "psychological_tension_axis",
        "purushartha_profile",
        "behavioral_risk_profile",
        "stability_metrics",
        "personality_vector",
        "probability_forecast",
        "karmic_pattern_profile",
        "interaction_risks",
        "enhanced_behavioral_risks",
    ]
    return {k: _json_safe(source.get(k, {})) for k in allowed_keys}



def _build_ai_input(context_data: str):
    system_message = SYSTEM_PROMPT
    user_message = USER_PROMPT_TEMPLATE.format(context_data=context_data)
    return system_message, user_message


# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# ??????????? AI Reading
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
@app.get("/ai_reading")
async def get_ai_reading(
    year: int = Query(...),
    month: int = Query(...),
    day: int = Query(...),
    hour: float = Query(...),
    lat: float = Query(..., ge=-90, le=90),
    lon: float = Query(..., ge=-180, le=180),
    house_system: str = Query("W"),  # Vedic uses Whole Sign by default
    include_nodes: int = Query(1),
    include_d9: int = Query(1),
    language: str = Query("ko"),
    gender: str = Query("male"),
    use_cache: int = Query(1),
    production_mode: int = Query(0),
    events_json: str = Query("[]"),
    timezone: Optional[float] = Query(None),
):
    """Generate AI reading."""
    cache_key = f"{year}_{month}_{day}_{hour}_{lat}_{lon}_{house_system}_{language}_{gender}_{production_mode}_{events_json}_{timezone}"

    if use_cache:
        cached = cache.get(cache_key)
        if cached:
            logger.info(f"Cache hit: {cache_key}")
            if production_mode:
                return cached
            return {
                "cached": True,
                "ai_cache_key": cache_key,
                **cached,
            }

    if production_mode:
        if not BTR_ENGINE_AVAILABLE:
            raise HTTPException(status_code=500, detail="BTR ?????????????????? ????????????")

        try:
            events = json.loads(events_json) if events_json else []
            if not isinstance(events, list) or not events:
                raise ValueError("production_mode=1 requires non-empty events_json list")

            birth_date = {"year": year, "month": month, "day": day}
            tz_offset = resolve_timezone_offset(year, month, day, lat, lon, timezone=timezone)
            btr_candidates = await asyncio.to_thread(
                analyze_birth_time,
                birth_date=birth_date,
                events=events,
                lat=lat,
                lon=lon,
                num_brackets=8,
                top_n=3,
                production_mode=True,
                tz_offset=tz_offset,
            )

            rectified_summary = await asyncio.to_thread(
                build_rectified_structural_summary,
                btr_candidates=btr_candidates,
                birth_date=birth_date,
                latitude=lat,
                longitude=lon,
                timezone=timezone,
            )
            report_payload = build_report_payload(rectified_summary)
            user_content = build_gpt_user_content(report_payload)

            if not async_client:
                final_text = json.dumps(report_payload["chapter_blocks"], ensure_ascii=False, sort_keys=True)
            else:
                response = await async_client.chat.completions.create(
                    model="gpt-4o",
                    temperature=0.3,
                    max_tokens=6000,
                    messages=[
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": user_content},
                    ],
                )
                final_text = response.choices[0].message.content

            production_result = {
                "report_text": final_text,
                "chapter_count": len(REPORT_CHAPTERS),
            }
            if use_cache:
                cache.set(cache_key, production_result)
            return production_result
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    chart = await asyncio.to_thread(
        get_chart,
        year=year,
        month=month,
        day=day,
        hour=hour,
        lat=lat,
        lon=lon,
        house_system=house_system,
        include_nodes=include_nodes,
        include_d9=include_d9,
        gender=gender,
        timezone=timezone,
    )
    structured_summary = await asyncio.to_thread(build_structural_summary, chart)
    ai_payload = {"structural_summary": structured_summary}

    summary = {
        "language": language,
        "structured_summary": structured_summary,
    }

    if not async_client:
        reading_text = "[OpenAI not configured]"
        result = {
            "cached": False,
            "fallback": True,
            "model": OPENAI_MODEL,
            "summary": summary,
            "structured_summary": structured_summary,
            "reading": reading_text,
            "ai_cache_key": cache_key,
            "debug_info": {
                "api_key_configured": bool(OPENAI_API_KEY),
                "api_key_length": len(OPENAI_API_KEY) if OPENAI_API_KEY else 0,
                "model_used": OPENAI_MODEL,
                "client_initialized": False,
                "reason": "OpenAI client not initialized",
            },
        }
        if use_cache:
            cache.set(cache_key, result)
        return result

    try:
        mapped_keys: list[str] = []
        mapped_texts: list[str] = []
        mapped_section_counts = {"atomic": 0, "lagna_lord": 0, "yogas": 0, "patterns": 0}
        static_context_used = False
        context_data = ""

        context_data = json.dumps(ai_payload, ensure_ascii=False, indent=2)
        system_message, user_message = _build_ai_input(context_data)

        openai_payload = {
            "model": OPENAI_MODEL,
            "messages": [
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message},
            ],
            "temperature": 0.6,
            "max_tokens": 8000,
        }
        try:
            response = await async_client.chat.completions.create(**openai_payload)
        except Exception as e:
            logger.error(f"OpenAI call failed: {e}")
            raise HTTPException(status_code=500, detail="AI generation error") from e

        logger.info("OpenAI response generated")
        reading_text = response.choices[0].message.content

        result = {
            "cached": False,
            "fallback": False,
            "model": OPENAI_MODEL,
            "summary": summary,
            "structured_summary": structured_summary,
            "reading": reading_text,
            "ai_cache_key": cache_key,
            "debug_info": {
                "api_key_configured": bool(OPENAI_API_KEY),
                "api_key_length": len(OPENAI_API_KEY) if OPENAI_API_KEY else 0,
                "model_used": OPENAI_MODEL,
                "system_prompt_length": len(system_message),
                "user_prompt_length": len(user_message),
                "context_length": len(context_data),
                "response_tokens": response.usage.total_tokens if hasattr(response, "usage") else 0,
                "client_initialized": async_client is not None,
                "static_context_used": static_context_used,
                "mapped_key_count": len(mapped_keys),
                "mapped_text_count": len(mapped_texts),
                "mapped_keys": mapped_keys,
                "mapped_section_counts": mapped_section_counts,
                "interpretations_loaded": bool(INTERPRETATIONS_KO),
                "interpretations_load_error": INTERPRETATIONS_LOAD_ERROR,
            },
        }

        if use_cache:
            cache.set(cache_key, result)

        return result

    except HTTPException:
        raise
    except Exception as e:
        reading_text = f"[AI Error: {str(e)}]"
        result = {
            "cached": False,
            "fallback": True,
            "error": str(e),
            "model": OPENAI_MODEL,
            "summary": summary,
            "structured_summary": structured_summary,
            "reading": reading_text,
            "ai_cache_key": cache_key,
            "debug_info": {
                "api_key_configured": bool(OPENAI_API_KEY),
                "api_key_length": len(OPENAI_API_KEY) if OPENAI_API_KEY else 0,
                "model_used": OPENAI_MODEL,
                "client_initialized": async_client is not None,
                "error_type": type(e).__name__,
                "error_message": str(e),
            },
        }
        return result

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# PDF ??????- ???????????????Flowable
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
class SouthIndianChart(Flowable):
    """????????????????????(??????????????????"""
    def __init__(self, chart_data, width=400, height=400, is_d9=False):
        Flowable.__init__(self)
        self.chart_data = chart_data
        self.width = width
        self.height = height
        self.is_d9 = is_d9
    
    def draw(self):
        c = self.canv
        w, h = self.width, self.height
        cx, cy = w / 2, h / 2
        size = min(w, h) * 0.8
        
        # ??????????????????????????
        pts = [
            (cx, cy + size/2),      # ???????
            (cx + size/2, cy),      # ??????
            (cx, cy - size/2),      # ???????
            (cx - size/2, cy),      # ???????
        ]
        
        c.setStrokeColor(colors.black)
        c.setLineWidth(2)
        
        # ???????????
        p = c.beginPath()
        p.moveTo(pts[0][0], pts[0][1])
        for i in range(1, 4):
            p.lineTo(pts[i][0], pts[i][1])
        p.close()
        c.drawPath(p, stroke=1, fill=0)
        
        # ???????????
        c.line(pts[0][0], pts[0][1], pts[2][0], pts[2][1])
        c.line(pts[1][0], pts[1][1], pts[3][0], pts[3][1])
        
        # ???????????????(??????????? 1???????????????????????
        houses_layout = [
            (cx, cy - size*0.15),           # 1
            (cx - size*0.25, cy - size*0.3), # 2
            (cx - size*0.35, cy - size*0.1), # 3
            (cx - size*0.35, cy + size*0.1), # 4
            (cx - size*0.25, cy + size*0.3), # 5
            (cx, cy + size*0.15),            # 6
            (cx + size*0.25, cy + size*0.3), # 7
            (cx + size*0.35, cy + size*0.1), # 8
            (cx + size*0.35, cy - size*0.1), # 9
            (cx + size*0.25, cy - size*0.3), # 10
            (cx + size*0.15, cy - size*0.1), # 11
            (cx - size*0.15, cy - size*0.1), # 12
        ]
        
        # ???????????????
        planets = self.chart_data.get("planets", {})
        house_contents = {i: [] for i in range(1, 13)}
        
        for name, data in planets.items():
            house_num = data.get("house")
            if house_num:
                abbrev = name[:2].upper() if len(name) <= 3 else name[:3]
                house_contents[house_num].append(abbrev)
        
        # ???????????????????
        c.setFont(PDF_FONT_REG, 9)
        for house_num, (x, y) in enumerate(houses_layout, 1):
            content = house_contents.get(house_num, [])
            if content:
                text = ", ".join(content)
                c.drawCentredString(x, y, text)

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# PDF ??????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
def create_pdf_styles():
    """PDF ???????????(config ?????????."""
    config = load_pdf_layout_config()
    font_cfg = config["fonts"]
    color_cfg = config["colors"]

    styles = getSampleStyleSheet()

    styles.add(ParagraphStyle(
        name='ReportTitle',
        parent=styles['Title'],
        fontName=PDF_FONT_BOLD,
        fontSize=font_cfg["title"],
        leading=font_cfg["title"] + 6,
        alignment=TA_CENTER,
        spaceAfter=12,
        textColor=colors.HexColor(color_cfg["title"]),
    ))

    styles.add(ParagraphStyle(
        name='ChapterTitle',
        parent=styles['Heading1'],
        fontName=PDF_FONT_BOLD,
        fontSize=font_cfg["chapter"],
        leading=font_cfg["chapter"] + 4,
        spaceAfter=12,
        textColor=colors.HexColor(color_cfg["chapter"]),
    ))

    styles.add(ParagraphStyle(
        name='Subtitle',
        parent=styles['Heading2'],
        fontName=PDF_FONT_BOLD,
        fontSize=font_cfg["subtitle"],
        leading=font_cfg["subtitle"] + 4,
        spaceAfter=6,
        textColor=colors.HexColor(color_cfg["chapter"]),
    ))

    styles.add(ParagraphStyle(
        name='Body',
        parent=styles['Normal'],
        fontName=PDF_FONT_REG,
        fontSize=font_cfg["body"],
        leading=16,
        alignment=TA_JUSTIFY,
        spaceAfter=8,
        textColor=colors.HexColor(color_cfg["body"]),
    ))

    styles.add(ParagraphStyle(
        name='Small',
        parent=styles['Normal'],
        fontName=PDF_FONT_REG,
        fontSize=font_cfg["small"],
        leading=font_cfg["small"] + 2,
        textColor=colors.grey,
        alignment=TA_CENTER,
    ))

    styles.add(ParagraphStyle(
        name='InsightSpike',
        parent=styles['Normal'],
        fontName=PDF_FONT_BOLD,
        fontSize=font_cfg["body"],
        leading=16,
        textColor=colors.HexColor(color_cfg["insight_spike"]),
        leftIndent=10,
        spaceAfter=12,
    ))

    return styles


def load_pdf_layout_config() -> dict[str, Any]:
    """PDF ????????????????????????????????????????????????????????fallback ????????"""
    config_path = Path(__file__).resolve().parent / "pdf_layout_config.json"
    default_config = {
        "page": {
            "size": "A4",
            "margin_top": 36,
            "margin_bottom": 36,
            "margin_left": 48,
            "margin_right": 48,
        },
        "fonts": {"title": 22, "chapter": 18, "subtitle": 14, "body": 12, "small": 10},
        "colors": {
            "title": "#222222",
            "chapter": "#111111",
            "body": "#444444",
            "insight_spike": "#A00000",
            "choice_fork": "#0033AA",
            "predictive": "#006633",
            "separator": "#CCCCCC",
        },
        "chapters": {},
    }

    try:
        with open(config_path, "r", encoding="utf-8") as f:
            loaded = json.load(f)
            if isinstance(loaded, dict):
                default_config.update({k: v for k, v in loaded.items() if k in default_config})
    except Exception as e:
        logger.warning(f"PDF layout config load failed. Using defaults: {e}")

    return default_config


def _sanitize_pdf_text(value: Any) -> str:
    """ReportLab Paragraph safe text conversion."""
    if value is None:
        return ""
    text = str(value)
    return text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")


def render_report_payload_to_pdf(report_payload: dict[str, Any], styles, config: dict[str, Any]) -> list:
    """Deterministic report payload??chapter-aware layout?????????????????????"""
    chapter_blocks = report_payload.get("chapter_blocks", {}) if isinstance(report_payload, dict) else {}
    if not isinstance(chapter_blocks, dict):
        return []

    elements: list[Any] = []
    chapter_config = config.get("chapters", {}) if isinstance(config.get("chapters"), dict) else {}
    color_cfg = config.get("colors", {}) if isinstance(config.get("colors"), dict) else {}
    separator_color = colors.HexColor(color_cfg.get("separator", "#CCCCCC"))
    choice_color = colors.HexColor(color_cfg.get("choice_fork", "#0033AA"))
    predictive_color = colors.HexColor(color_cfg.get("predictive", "#006633"))

    for chapter in REPORT_CHAPTERS:
        fragments = chapter_blocks.get(chapter, [])
        if not isinstance(fragments, list) or not fragments:
            continue

        if elements and chapter_config.get(chapter, {}).get("break_before"):
            elements.append(PageBreak())

        elements.append(Paragraph(_sanitize_pdf_text(chapter), styles["ChapterTitle"]))
        elements.append(Spacer(1, 8))

        for fragment in fragments:
            if not isinstance(fragment, dict):
                continue

            if "spike_text" in fragment:
                elements.append(Paragraph(_sanitize_pdf_text(fragment.get("spike_text", "")), styles["InsightSpike"]))
                elements.append(Spacer(1, 8))
                continue

            for field in ("title", "summary", "analysis", "implication"):
                value = fragment.get(field)
                if not value:
                    continue
                style_name = "Subtitle" if field == "title" else "Body"
                elements.append(Paragraph(_sanitize_pdf_text(value), styles[style_name]))

            choice_fork = fragment.get("choice_fork")
            if isinstance(choice_fork, str) and choice_fork.strip():
                elements.append(Paragraph(_sanitize_pdf_text(choice_fork), styles["Body"]))
            elif isinstance(choice_fork, dict):
                path_a = choice_fork.get("path_a", {}) if isinstance(choice_fork.get("path_a"), dict) else {}
                path_b = choice_fork.get("path_b", {}) if isinstance(choice_fork.get("path_b"), dict) else {}
                table_rows = [
                    ["Path", "Trajectory"],
                    [f"A: {_sanitize_pdf_text(path_a.get('label', '-'))}", _sanitize_pdf_text(path_a.get("trajectory", "-"))],
                    ["Emotional Cost", _sanitize_pdf_text(path_a.get("emotional_cost", "-"))],
                    [f"B: {_sanitize_pdf_text(path_b.get('label', '-'))}", _sanitize_pdf_text(path_b.get("trajectory", "-"))],
                    ["Emotional Cost", _sanitize_pdf_text(path_b.get("emotional_cost", "-"))],
                ]
                choice_table = Table(table_rows, colWidths=[120, 350])
                choice_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), choice_color),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                    ('FONTNAME', (0, 0), (-1, 0), PDF_FONT_BOLD),
                    ('FONTNAME', (0, 1), (-1, -1), PDF_FONT_REG),
                    ('GRID', (0, 0), (-1, -1), 0.5, separator_color),
                    ('VALIGN', (0, 0), (-1, -1), 'TOP'),
                    ('LEFTPADDING', (0, 0), (-1, -1), 6),
                    ('RIGHTPADDING', (0, 0), (-1, -1), 6),
                ]))
                elements.append(choice_table)
            elements.append(Spacer(1, 10))

            predictive = fragment.get("predictive_compression")
            if isinstance(predictive, dict):
                predictive_rows = [
                    ["Window", _sanitize_pdf_text(predictive.get("window", "-"))],
                    ["Dominant Theme", _sanitize_pdf_text(predictive.get("dominant_theme", "-"))],
                    ["Probability", _sanitize_pdf_text(predictive.get("probability_strength", "-"))],
                    ["Warning", _sanitize_pdf_text(predictive.get("structural_warning", "-"))],
                    ["Alignment", _sanitize_pdf_text(predictive.get("recommended_alignment", "-"))],
                ]
                predictive_table = Table(predictive_rows, colWidths=[150, 320])
                predictive_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), predictive_color),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                    ('FONTNAME', (0, 0), (-1, 0), PDF_FONT_BOLD),
                    ('FONTNAME', (0, 1), (-1, -1), PDF_FONT_REG),
                    ('GRID', (0, 0), (-1, -1), 0.5, separator_color),
                    ('VALIGN', (0, 0), (-1, -1), 'TOP'),
                ]))
                elements.append(predictive_table)
                elements.append(Spacer(1, 12))

    return elements

def parse_markdown_to_flowables(text: str, styles):
    """?????????????????????? ???????Flowables"""
    flowables = []
    lines = text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            flowables.append(Spacer(1, 0.2*cm))
            continue
        
        # Heading
        if line.startswith('### '):
            clean_line = line[4:].replace('**', '')  # Remove bold markers from headings
            flowables.append(Paragraph(clean_line, styles['Subtitle']))
        elif line.startswith('## '):
            clean_line = line[3:].replace('**', '')
            flowables.append(Paragraph(clean_line, styles['ChapterTitle']))
        elif line.startswith('# '):
            clean_line = line[2:].replace('**', '')
            flowables.append(Paragraph(clean_line, styles['ReportTitle']))
        # Section markers
        elif line.startswith('[') and line.endswith(']'):
            flowables.append(Spacer(1, 0.3*cm))
            clean_line = line.replace('**', '')
            flowables.append(Paragraph(f"<b>{clean_line}</b>", styles['ChapterTitle']))
        # List
        elif line.startswith('- ') or line.startswith('* '):
            clean_line = convert_markdown_bold(line[2:])
            flowables.append(Paragraph('??' + clean_line, styles['Body']))
        else:
            # Regular paragraph
            clean_line = convert_markdown_bold(line)
            flowables.append(Paragraph(clean_line, styles['Body']))
    
    return flowables

def convert_markdown_bold(text: str) -> str:
    """Convert **bold** to <b>bold</b> safely"""
    import re
    # Replace **text** with <b>text</b>
    # Use regex to properly match pairs
    result = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', text)
    return result

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# ??????????? PDF ??????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
@app.get("/pdf")
async def generate_pdf(
    year: int = Query(...),
    month: int = Query(...),
    day: int = Query(...),
    hour: float = Query(...),
    lat: float = Query(..., ge=-90, le=90),
    lon: float = Query(..., ge=-180, le=180),
    house_system: str = Query("W"),  # Vedic uses Whole Sign by default
    include_nodes: int = Query(1),
    include_d9: int = Query(1),
    include_ai: int = Query(1),
    language: str = Query("ko"),
    gender: str = Query("male"),
    timezone: Optional[float] = Query(None),
    ai_cache_key: str = Query(None),
    cache_only: int = Query(0)
):
    """Generate PDF report."""
    from io import BytesIO
    
    # ????????????????
    chart = await asyncio.to_thread(
        get_chart,
        year=year,
        month=month,
        day=day,
        hour=hour,
        lat=lat,
        lon=lon,
        house_system=house_system,
        include_nodes=include_nodes,
        include_d9=include_d9,
        gender=gender,
        timezone=timezone,
    )
    
    # AI ???????
    ai_reading = None
    if include_ai:
        if cache_only and ai_cache_key and cache.get(ai_cache_key):
            ai_reading = cache.get(ai_cache_key)
        else:
            ai_reading = await get_ai_reading(
                year, month, day, hour, lat, lon,
                house_system, include_nodes, include_d9,
                language, gender, use_cache=1, timezone=timezone
            )
    
    layout_config = load_pdf_layout_config()
    page_cfg = layout_config.get("page", {}) if isinstance(layout_config.get("page"), dict) else {}

    # PDF ??????
    with BytesIO() as buffer:
        doc = SimpleDocTemplate(
            buffer,
            pagesize=A4,
            rightMargin=float(page_cfg.get("margin_right", 48)),
            leftMargin=float(page_cfg.get("margin_left", 48)),
            topMargin=float(page_cfg.get("margin_top", 36)),
            bottomMargin=float(page_cfg.get("margin_bottom", 36)),
        )

        story = []
        styles = create_pdf_styles()
        # Report title
        title_text = "Vedic Astrology Report"
        story.append(Paragraph(title_text, styles['ReportTitle']))
        story.append(Spacer(1, 0.5*cm))

        # Birth information
        birth_info = (
            f"<b>Birth Information</b><br/>"
            f"Date: {year}-{month:02d}-{day:02d}<br/>"
            f"Time: {int(hour)}:{int((hour % 1) * 60):02d}<br/>"
            f"Location: {lat:.4f}N, {lon:.4f}E"
        )
        story.append(Paragraph(birth_info, styles['Body']))
        story.append(Paragraph(birth_info, styles['Body']))
        story.append(Spacer(1, 0.5*cm))

        # D1 ?????????
        story.append(Paragraph("D1 ?????????(Rasi)" if language == "ko" else "D1 Chart (Rasi)", styles['ChapterTitle']))
        story.append(SouthIndianChart(chart, width=350, height=350))
        story.append(Spacer(1, 0.5*cm))

        # ?????????????
        story.append(Paragraph("Planetary Positions", styles['ChapterTitle']))

        planet_data = [["Planet", "Sign", "House", "Nakshatra", "Dignity"]]

        for name, data in chart["planets"].items():
            rasi = data["rasi"]["name_kr" if language == "ko" else "name"]
            house = str(data.get("house", "-"))
            nak = data["nakshatra"]["name"]
            dignity = data["features"]["dignity"]
            planet_data.append([name, rasi, house, nak, dignity])

        planet_table = Table(planet_data, colWidths=[3*cm, 4*cm, 2*cm, 4*cm, 3*cm])
        planet_table.setStyle(TableStyle([
            ('FONTNAME', (0, 0), (-1, 0), PDF_FONT_BOLD),
            ('FONTNAME', (0, 1), (-1, -1), PDF_FONT_REG),
            ('FONTSIZE', (0, 0), (-1, -1), 9),
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.black),
            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.lightgrey]),
        ]))
        story.append(planet_table)
        story.append(Spacer(1, 0.5*cm))

        report_payload = build_report_payload({"structural_summary": build_structural_summary(chart)})
        deterministic_elements = render_report_payload_to_pdf(report_payload, styles, layout_config)
        if deterministic_elements:
            story.append(PageBreak())
            story.extend(deterministic_elements)

        # D9 ?????????(?????
        if include_d9 and "d9" in chart:
            story.append(PageBreak())
            story.append(Paragraph("D9 ?????????(Navamsa)" if language == "ko" else "D9 Chart (Navamsa)", styles['ChapterTitle']))
            story.append(SouthIndianChart(chart, width=350, height=350, is_d9=True))
            story.append(Spacer(1, 0.5*cm))

        # ???????????????AI ???????fallback
        if (not deterministic_elements) and ai_reading and ai_reading.get("reading"):
            story.append(PageBreak())
            story.append(Paragraph("AI Detailed Reading", styles['ChapterTitle']))
            story.append(Spacer(1, 0.3*cm))

            reading_text = ai_reading["reading"]
            flowables = parse_markdown_to_flowables(reading_text, styles)
            story.extend(flowables)

        # PDF ??????
        doc.build(story)
        pdf_bytes = buffer.getvalue()
    
    return Response(
        content=pdf_bytes,
        media_type="application/pdf",
        headers={"Content-Disposition": "attachment; filename=vedic_report.pdf"}
    )

# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# BTR (Birth Time Rectification) ???????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
from fastapi import Body

# BTR ????????????????????????????
BTR_QUESTIONS_PATH = os.path.join(os.path.dirname(__file__), "btr_questions.json")
BTR_QUESTIONS = {}
try:
    if os.path.exists(BTR_QUESTIONS_PATH):
        with open(BTR_QUESTIONS_PATH, "r", encoding="utf-8") as f:
            BTR_QUESTIONS = json.load(f)
        logger.info(f"BTR questions loaded: {BTR_QUESTIONS_PATH}")
    else:
        logger.warning(f"BTR questions file not found: {BTR_QUESTIONS_PATH}")
except Exception as e:
    logger.warning(f"BTR questions load failed: {e}")

# BTR ???????import
try:
    # Import BTR engine functions from the backend package so module resolution
    # remains consistent regardless of the current working directory.
    from backend.btr_engine import (
        analyze_birth_time,
        refine_time_bracket,
        generate_time_brackets,
        calculate_vimshottari_dasha,
        get_dasha_at_date,
        convert_age_range_to_year_range,
    )
    from backend.tuning_analyzer import (
        analyze_tuning_data,
        compute_weight_adjustments,
        apply_weight_adjustments,
    )
    BTR_ENGINE_AVAILABLE = True
    logger.info("BTR engine loaded successfully")
except ImportError as e:
    BTR_ENGINE_AVAILABLE = False
    logger.warning(f"BTR engine not available: {e}")


def _get_age_group(age: int) -> str:
    """Return age-grouped BTR questions."""
    if age < 30:
        return "20s"
    elif age < 50:
        return "30s_40s"
    else:
        return "50s_plus"


@app.get("/btr/questions")
def get_btr_questions(
    age: int = Query(..., ge=10, le=120, description="Age"),
    language: str = Query("ko", description="Language (ko/en)")
):
    """
    BTR ???????????????????(??????????

    - ??????????????????10??+ ???????????????????????????3??
    - ??13?????????????????????
    """
    if not BTR_QUESTIONS:
        raise HTTPException(status_code=500, detail="BTR ????????????????????? ?????????? ????????????")

    common = BTR_QUESTIONS.get("common_questions", [])
    age_group = _get_age_group(age)
    age_specific = BTR_QUESTIONS.get("age_group_questions", {}).get(age_group, [])

    all_questions = common + age_specific

    # ????????????????????????
    formatted = []
    for q in all_questions:
        text_key = "text_ko" if language == "ko" else "text_en"
        options_formatted = {}
        for opt_key, opt_val in q.get("options", {}).items():
            opt_text_key = "text_ko" if language == "ko" else "text_en"
            options_formatted[opt_key] = opt_val.get(opt_text_key, opt_val.get("text_ko", ""))

        formatted.append({
            "id": q["id"],
            "text": q.get(text_key, q.get("text_ko", "")),
            "text_ko": q.get("text_ko", ""),
            "text_en": q.get("text_en", ""),
            "type": q["type"],
            "options": options_formatted,
            "event_type": q.get("event_type", ""),
            "weight": q.get("weight", 1.0),
            "dasha_lords": q.get("dasha_lords", []),
            "house_triggers": q.get("house_triggers", []),
        })

    return {
        "age": age,
        "age_group": age_group,
        "language": language,
        "total_questions": len(formatted),
        "questions": formatted,
    }


@app.post("/btr/analyze")
def analyze_btr(request: BTRAnalyzeRequest):
    """
    BTR ??????????????

    Request Body:
    {
        "year": 1994,
        "month": 12,
        "day": 18,
        "lat": 37.5665,
        "lon": 126.978,
        "events": [
            {
                "type": "relationship",
                "year": 2015,
                "precision_level": "exact",
                "weight": 0.8,
                "dasha_lords": ["Venus", "Jupiter"],
                "house_triggers": [7]
            }
        ]
    }

    Returns:
        Top 3 ??????????????? + ????????
    """
    if not BTR_ENGINE_AVAILABLE:
        raise HTTPException(status_code=500, detail="BTR ?????????????????? ????????????")

    validate_btr_events(request.events)

    # ??????????????????????(precision_level ??
    current_year = datetime.utcnow().year
    for ev in request.events:
        if ev.precision_level == "exact":
            if ev.year is not None and ev.year > current_year:
                raise HTTPException(
                    status_code=400,
                    detail=f"??????????????????????????????????????????: {ev.year}"
                )
        elif ev.precision_level == "range":
            if ev.age_range is None:
                raise HTTPException(
                    status_code=400,
                    detail="range ????????????age_range?????? ???????????????"
                )
            start_year, _ = convert_age_range_to_year_range(request.year, ev.age_range)
            if start_year > current_year:
                raise HTTPException(
                    status_code=400,
                    detail="Age range results in a future event. Please adjust the range."
                )
        elif ev.precision_level == "unknown":
            # unknown?? ??????????????????????????????
            continue

    try:
        birth_date = {"year": request.year, "month": request.month, "day": request.day}

        # Pydantic ??????????dict??????????
        events_dict = [ev.model_dump(mode="json") for ev in request.events]

        tz_offset = resolve_timezone_offset(
            request.year,
            request.month,
            request.day,
            request.lat,
            request.lon,
            timezone=request.timezone,
        )
        candidates = analyze_birth_time(
            birth_date=birth_date,
            events=events_dict,
            lat=request.lat,
            lon=request.lon,
            num_brackets=8,
            top_n=3,
            tune_mode=request.tune_mode,
            tz_offset=tz_offset,
        )

        return {
            "status": "ok",
            "birth_date": birth_date,
            "lat": request.lat,
            "lon": request.lon,
            "total_events": len(request.events),
            "candidates": candidates,
        }

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"BTR ?????????????? {str(e)}")


@app.post("/btr/refine")
def refine_btr(request: BTRRefineRequest):
    """
    ??????????????2???????(30?????????

    Returns:
        ?????????????6??????????
    """
    if not BTR_ENGINE_AVAILABLE:
        raise HTTPException(status_code=500, detail="BTR ?????????????????? ????????????")

    validate_btr_events(request.events)

    # ??????????????????????(precision_level ??
    current_year = datetime.utcnow().year
    for ev in request.events:
        if ev.precision_level == "exact":
            if ev.year is not None and ev.year > current_year:
                raise HTTPException(
                    status_code=400,
                    detail=f"??????????????????????????????????????????: {ev.year}"
                )
        elif ev.precision_level == "range":
            if ev.age_range is None:
                raise HTTPException(
                    status_code=400,
                    detail="range ????????????age_range?????? ???????????????"
                )
            start_year, _ = convert_age_range_to_year_range(request.year, ev.age_range)
            if start_year > current_year:
                raise HTTPException(
                    status_code=400,
                    detail="Age range results in a future event. Please adjust the range."
                )
        elif ev.precision_level == "unknown":
            continue

    try:
        birth_date = {"year": request.year, "month": request.month, "day": request.day}
        bracket = {"start": request.bracket_start, "end": request.bracket_end}

        # Pydantic ??????????dict??????????
        events_dict = [ev.model_dump(mode="json") for ev in request.events]

        refined = refine_time_bracket(
            date=birth_date,
            bracket=bracket,
            events=events_dict,
            lat=request.lat,
            lon=request.lon,
            sub_intervals=6,
        )

        return {
            "status": "ok",
            "birth_date": birth_date,
            "original_bracket": bracket,
            "refined_candidates": refined,
        }

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"BTR ????????????? {str(e)}")


@app.post("/btr/admin/recalculate-weights")
def recalculate_btr_weights():
    """Admin endpoint for empirical weight adjustment recalculation."""
    if os.getenv("BTR_ENABLE_TUNE_MODE", "0") != "1":
        raise HTTPException(status_code=403, detail="Tune mode is disabled.")

    tuning_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "tuning_inputs.log")
    profile_path = os.path.join(os.path.dirname(__file__), "config", "event_signal_profile.json")

    stats = analyze_tuning_data(tuning_path)
    adjustments = compute_weight_adjustments(stats)
    output_path = apply_weight_adjustments(profile_path, adjustments)

    applied_changes = []
    for event_type, multiplier in adjustments.items():
        applied_changes.append({
            "event_type": event_type,
            "multiplier": round(float(multiplier), 6),
            "stats": stats.get(event_type, {}),
        })

    return {
        "status": "ok",
        "tuning_log": tuning_path,
        "profile_output": output_path,
        "events_updated": len(applied_changes),
        "adjustments": applied_changes,
    }


# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
# ????????
# ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
if __name__ == "__main__":
    import uvicorn
    init_fonts()
    uvicorn.run(app, host="0.0.0.0", port=8000)

